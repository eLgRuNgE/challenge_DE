{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ0khVFTIwKp"
      },
      "source": [
        "# Data Engineer Challenge\n",
        "\n",
        "En este desafío, realizo un análisis de datos sobre un conjunto de tweets relacionados con las protestas de agricultores. Utilizaremos Python y algunas herramientas como para el desarrollo como `unittest`,`memory_profiler` y `Jupyter Notebook` para llevar a cabo este análisis.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*Para cada una de las funciones requeridas en el desafio muestro los 3 intentos más destacados (incluida la función final definitiva) en donde voy narrando lo más detalladamente posible lo que hice para llegar a la solución final.*\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## - Preparación del entorno\n",
        "\n",
        "A nivel local se crea un repositorio en gitHub entorno virtual que sirven para el inicio del desarrollo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6lGu9I9IwKt"
      },
      "source": [
        "## Instalación de los requerimientos:   \n",
        "\n",
        "Dentro del entorno virtual o el Jupyter Notebook se instalan los paquetes requeridos desde requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e86ENRr_IwKt",
        "outputId": "265425dc-cca2-417d-c3cb-f6b2c3ea6448",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: appnope==0.1.4 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 1)) (0.1.4)\n",
            "Requirement already satisfied: asttokens==2.4.1 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 2)) (2.4.1)\n",
            "Requirement already satisfied: certifi==2024.2.2 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 3)) (2024.2.2)\n",
            "Requirement already satisfied: charset-normalizer==3.3.2 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: comm==0.2.2 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 5)) (0.2.2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: debugpy==1.8.1 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 6)) (1.8.1)\n",
            "Requirement already satisfied: decorator==5.1.1 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 7)) (5.1.1)\n",
            "Requirement already satisfied: emoji==2.10.1 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 8)) (2.10.1)\n",
            "Requirement already satisfied: executing==2.0.1 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 9)) (2.0.1)\n",
            "Requirement already satisfied: idna==3.6 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 10)) (3.6)\n",
            "Requirement already satisfied: ipykernel==6.29.3 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 11)) (6.29.3)\n",
            "Requirement already satisfied: ipython==8.22.2 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 12)) (8.22.2)\n",
            "Requirement already satisfied: jedi==0.19.1 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 13)) (0.19.1)\n",
            "Requirement already satisfied: jupyter_client==8.6.1 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 14)) (8.6.1)\n",
            "Requirement already satisfied: jupyter_core==5.7.2 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 15)) (5.7.2)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.6 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 16)) (0.1.6)\n",
            "Requirement already satisfied: memory-profiler==0.61.0 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 17)) (0.61.0)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 18)) (1.6.0)\n",
            "Requirement already satisfied: packaging==24.0 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 19)) (24.0)\n",
            "Requirement already satisfied: parso==0.8.3 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 20)) (0.8.3)\n",
            "Requirement already satisfied: pexpect==4.9.0 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 21)) (4.9.0)\n",
            "Requirement already satisfied: platformdirs==4.2.0 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 22)) (4.2.0)\n",
            "Requirement already satisfied: prompt-toolkit==3.0.43 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 23)) (3.0.43)\n",
            "Requirement already satisfied: psutil==5.9.8 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 24)) (5.9.8)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 25)) (0.7.0)\n",
            "Requirement already satisfied: pure-eval==0.2.2 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 26)) (0.2.2)\n",
            "Requirement already satisfied: Pygments==2.17.2 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 27)) (2.17.2)\n",
            "Requirement already satisfied: python-dateutil==2.9.0.post0 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 28)) (2.9.0.post0)\n",
            "Requirement already satisfied: pyzmq==25.1.2 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 29)) (25.1.2)\n",
            "Requirement already satisfied: requests==2.31.0 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 30)) (2.31.0)\n",
            "Requirement already satisfied: six==1.16.0 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 31)) (1.16.0)\n",
            "Requirement already satisfied: stack-data==0.6.3 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 32)) (0.6.3)\n",
            "Requirement already satisfied: tornado==6.4 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 33)) (6.4)\n",
            "Requirement already satisfied: traitlets==5.14.2 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 34)) (5.14.2)\n",
            "Requirement already satisfied: urllib3==2.2.1 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 35)) (2.2.1)\n",
            "Requirement already satisfied: wcwidth==0.2.13 in /Users/fabiancallejas/DevelopmentLocal-MBA_XIX/LATAM/challenge_DE/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 36)) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Instalar los paquetes desde requirements.txt\n",
        "!pip install -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxBk3q2NIwKu"
      },
      "source": [
        "Se cargan los datos desde JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "E9zY2YRFIwKu"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import io\n",
        "import requests\n",
        "\n",
        "# URL del archivo ZIP\n",
        "url = \"https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/data/tweets.json.zip\"\n",
        "\n",
        "# Descargar el archivo ZIP\n",
        "response = requests.get(url)\n",
        "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
        "\n",
        "# Obtengo el archivo requerido\n",
        "target_file_name = \"farmers-protest-tweets-2021-2-4.json\"\n",
        "zip_file.extract(target_file_name)\n",
        "\n",
        "# Ahora `target_file_name` está disponible en el directorio actual de Colab\n",
        "test_file_path = target_file_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBpctVKKmPvI"
      },
      "source": [
        "# **Reto #1**\n",
        "\n",
        "Las top 10 fechas donde hay más tweets. Mencionar el usuario (username) que más publicaciones tiene por cada uno de esos días. Debe incluir las siguientes funciones:\n",
        "\n",
        "```python\n",
        "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "```\n",
        "```python\n",
        "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "```\n",
        "```python\n",
        "Returns:\n",
        "[(datetime.date(1999, 11, 15), \"LATAM321\"), (datetime.date(1999, 7, 15), \"LATAM_CHI\"), ...]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K97hLzNMhBx"
      },
      "source": [
        "# **R#1 - Enfoque 1:** Optimización del tiempo de ejecución."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWrqdxWQMtUG"
      },
      "source": [
        "### ***- Primer intento:*** función `q1_time`\n",
        "\n",
        "La solución más obvia a este problema es usar la clase `defaultdict` que se encuentra en el módulo `collections` de Python. Funciona de manera similar a un diccionario convencional (dict), pero con una diferencia clave: automáticamente crea valores por defecto para claves que aún no están en el diccionario. Esto significa que no es necesario preocuparse por verificar si una clave existe antes de acceder a ella o asignarle un valor.\n",
        "\n",
        "En esta implementación también se lee el archivo linea por linea para mejorar el uso de memoria y no cargar todo el archivo json en memoria.\n",
        "\n",
        "\n",
        "***Descripción detallada:***\n",
        "\n",
        "***1.   Lectura del archivo JSON:***\n",
        "*   La función comienza abriendo el archivo JSON especificado en el parámetro `file_path` en modo de lectura.\n",
        "*   Luego lee todas las líneas del archivo y carga los datos en una lista de listas.\n",
        "*   Cada sublista contiene la fecha del tweet y el nombre de usuario del autor del tweet.\n",
        "*   Estos datos se extraen del JSON utilizando la función `json.loads(line)['date'].split('T')[0]` para obtener la fecha y `json.loads(line)['user']['username']` para obtener el nombre de usuario.\n",
        "\n",
        "***2.   Procesamiento de los datos:***\n",
        "*   Se utiliza un diccionario para almacenar los pares fecha - usuario y sus respectivos conteos de tweets.\n",
        "*   Para cada tweet en el archivo, se extrae la fecha y el nombre de usuario.\n",
        "*   Luego, se actualiza el contador de tweets por usuario y fecha en el diccionario.\n",
        "\n",
        "***3.   Determinación de las fechas más comunes:***\n",
        "*   Utilizando `sorted()` y `key`, se determinan las 10 fechas más comunes en el diccionario.\n",
        "*   Las fechas se ordenan según el número total de tweets publicados en cada una de ellas.\n",
        "\n",
        "***4.   Obtención del usuario más activo por fecha:***\n",
        "*   Para cada una de las fechas más comunes, se determina el usuario más activo.\n",
        "*   Esto se logra encontrando el usuario con el mayor número de tweets para esa fecha en particular.\n",
        "\n",
        "***5.   Formateo de las fechas:***\n",
        "*   Las fechas extraídas inicialmente están en formato de cadena de texto.\n",
        "*   Se utilizan para crear objetos datetime.date utilizando la función `datetime.strptime()` para convertirlas al formato deseado.\n",
        "\n",
        "***6.   Agrupación de las fechas y usuarios:***\n",
        "*   Finalmente, se combinan las fechas formateadas y los usuarios más activos en una lista de tuplas.\n",
        "*   Cada tupla contiene una fecha y el usuario más activo para esa fecha.\n",
        "\n",
        "***7.   Retorno de resultados:***\n",
        "*   La función devuelve la lista de tuplas que contiene las 10 fechas principales con los usuarios más activos para cada una de esas fechas.\n",
        "*   Esta función proporciona una manera eficiente de analizar datos de tweets y obtener información sobre las fechas y usuarios más activos en la plataforma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "r-kDeEWvOD05"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "from datetime import datetime\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q1_time_attempt_1(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "    \"\"\"\n",
        "    Esta función analiza un archivo JSON que contiene registros de tweets y devuelve las 10 fechas\n",
        "    más comunes junto con el usuario más activo para cada fecha.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): La ruta del archivo JSON que contiene los registros de tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[datetime.date, str]]: Una lista de tuplas, donde cada tupla contiene una fecha\n",
        "        y el usuario más activo para esa fecha.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si no se encuentra el archivo especificado en file_path.\n",
        "    \"\"\"\n",
        "\n",
        "    # Paso 1: Lectura del archivo JSON\n",
        "    dates_dict = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    # Paso 2: Procesamiento de los datos\n",
        "    with open(file_path, 'r') as data:\n",
        "        for line_data in data:\n",
        "            tweet = json.loads(line_data)\n",
        "            tweet_date = tweet['date'].split('T')[0]\n",
        "            username = tweet['user']['username']\n",
        "\n",
        "            # Actualización del contador de tweets por usuario y fecha\n",
        "            dates_dict[tweet_date][username] += 1\n",
        "\n",
        "    # Paso 3: Determinación de las fechas más comunes\n",
        "    top_dates = sorted(dates_dict.keys(), key=lambda x: sum(dates_dict[x].values()), reverse=True)[:10]\n",
        "\n",
        "    # Paso 4: Obtención del usuario más activo por fecha\n",
        "    top_users = [max(dates_dict[date], key=dates_dict[date].get) for date in top_dates]\n",
        "\n",
        "    # Paso 5: Formateo de las fechas\n",
        "    top_dates = [datetime.strptime(date_str, \"%Y-%m-%d\").date() for date_str in top_dates]\n",
        "\n",
        "    # Paso 6: Agrupación de las fechas y usuarios\n",
        "    result = list(zip(top_dates, top_users))\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgjxxV2BPK6B"
      },
      "source": [
        "### ***- Segundo intento:*** función `q1_time`\n",
        "\n",
        "La función `q1_time` procesa un archivo JSON que contiene registros de tweets y devuelve las 10 fechas más comunes junto con el usuario más activo para cada fecha.\n",
        "\n",
        "***Descripción detallada:***\n",
        "\n",
        "***1.   Obtención de los datos de fecha y usuario:***\n",
        "*   Primero se guardan los datos de fecha y nombre de usuario en una lista de listas, para poder contarlos correctamente.\n",
        "*   Se abre el archivo especificado en `file_path` y se lee línea por línea.\n",
        "*   Los datos se almacenan en una lista donde cada elemento es otra lista que contiene la fecha del tweet y el nombre de usuario del autor.\n",
        "\n",
        "***2.   Determinación de las fechas más comunes:***\n",
        "*   Se utiliza la clase `Counter()` junto con list comprehension para obtener las 10 fechas más comunes de todos los tweets.\n",
        "*   Se cuentan las ocurrencias de cada fecha en la lista de datos y se obtienen las 10 fechas más comunes utilizando el método `most_common(10)`.\n",
        "\n",
        "***3.   Obtención del usuario más activo por fecha:***\n",
        "*   De manera similar, se obtiene el usuario que más tweeteó para cada una de las fechas más comunes.\n",
        "*   Se filtran los datos para cada fecha común y se cuentan las ocurrencias de cada usuario.\n",
        "*   Se selecciona el usuario con mayor cantidad de tweets para cada fecha común.\n",
        "\n",
        "***4.   Formateo de las fechas y agrupación con los usuarios:***\n",
        "*   Se utilizan las fechas obtenidas anteriormente y se las convierte al formato `datetime.date` utilizando la función `datetime.strptime()`.\n",
        "*   Se combinan las fechas formateadas y los usuarios más activos en una lista de tuplas.\n",
        "\n",
        "***5.   Retorno de resultados:***\n",
        "*   La función devuelve la lista de tuplas que contiene las 10 fechas principales con los usuarios más activos para cada una de esas fechas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "rECFJEOsPNLE"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q1_time_attempt_2(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "    \"\"\"\n",
        "    Esta función procesa un archivo JSON que contiene registros de tweets y devuelve las 10 fechas más comunes junto con el usuario más activo para cada fecha.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): La ruta del archivo JSON que contiene los registros de tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[datetime.date, str]]: Una lista de tuplas, donde cada tupla contiene una fecha y el usuario más activo para esa fecha.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si el archivo especificado en file_path no se encuentra.\n",
        "    \"\"\"\n",
        "    # Paso 1: Obtención de los datos de fecha y usuario\n",
        "    with open(file_path, 'r') as data:\n",
        "        tweets_dates_users = [[json.loads(line)['date'].split('T')[0], json.loads(line)['user']['username']] for line in data.readlines()]\n",
        "\n",
        "    # Paso 2: Determinación de las fechas más comunes\n",
        "    most_common_dates = Counter([d[0] for d in tweets_dates_users]).most_common(10)\n",
        "\n",
        "    # Paso 3: Obtención del usuario más activo para cada fecha más común\n",
        "    most_common_users = [Counter([d[1] for d in tweets_dates_users if d[0] == date[0]]).most_common(1)[0][0] for date in most_common_dates]\n",
        "\n",
        "    # Paso 4: Formateo de las fechas y agrupación con los usuarios\n",
        "    result = list(zip([datetime.strptime(date[0], \"%Y-%m-%d\").date() for date in most_common_dates], most_common_users))\n",
        "\n",
        "    # Paso 5: Retorno de resultados\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zp-R-3QPONr"
      },
      "source": [
        "### ***- Intento Final:*** función `q1_time`\n",
        "\n",
        "\n",
        "En este intento no se almacenan los datos directamente en una lista donde cada elemento es otra lista que contiene la fecha del tweet y el nombre de usuario del autor. Tampoco se utiliza la clase Counter para optimizar la ejecución de la función `q1_time`.\n",
        "\n",
        "***Descripción detallada:***\n",
        "\n",
        "***1.   Obtención de los datos de fecha y usuario:***\n",
        "*   Primero se leen todas las líneas del archivo JSON especificado en el parámetro `file_path`.\n",
        "*   Los datos se almacenan en una lista de listas, donde cada sublista contiene la fecha del tweet y el nombre de usuario del autor.\n",
        "\n",
        "***2.   Determinación de las fechas más comunes:***\n",
        "*   Se cuenta la frecuencia de cada fecha en la lista de datos para obtener las 10 fechas más comunes.\n",
        "*   No se utiliza la clase `Counter` para optimizar el código y se realiza el conteo manualmente.\n",
        "\n",
        "***3.   Obtención del usuario más activo por fecha:***\n",
        "*   Para cada una de las fechas más comunes, se filtran los datos y se cuentan las ocurrencias de cada usuario.\n",
        "*   Se selecciona el usuario con mayor cantidad de tweets para cada fecha común.\n",
        "\n",
        "***4.   Formateo de las fechas y agrupación con los usuarios:***\n",
        "*   Se utilizan las fechas obtenidas anteriormente y se las convierte al formato `datetime.date` utilizando la función `datetime.strptime()`.\n",
        "*   Se combinan las fechas formateadas y los usuarios más activos en una lista de tuplas.\n",
        "\n",
        "***5.   Retorno de resultados:***\n",
        "*   La función devuelve la lista de tuplas que contiene las 10 fechas principales con los usuarios más activos para cada una de esas fechas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "7OJ5FXOjPPZN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "    \"\"\"\n",
        "    Esta función procesa un archivo JSON que contiene registros de tweets y devuelve las 10 fechas más comunes junto con el usuario más activo para cada fecha.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): La ruta del archivo JSON que contiene los registros de tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[datetime.date, str]]: Una lista de tuplas, donde cada tupla contiene una fecha y el usuario más activo para esa fecha.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si el archivo especificado en file_path no se encuentra.\n",
        "    \"\"\"\n",
        "    # Paso 1: Obtención de los datos de fecha y usuario\n",
        "    tweets_dates_users = []\n",
        "    with open(file_path, 'r') as data:\n",
        "        for line in data.readlines():\n",
        "            tweet = json.loads(line)\n",
        "            tweet_date = tweet['date'].split('T')[0]\n",
        "            username = tweet['user']['username']\n",
        "            tweets_dates_users.append((tweet_date, username))\n",
        "\n",
        "    # Paso 2: Determinación de las fechas más comunes\n",
        "    date_counts = {}\n",
        "    for tweet_date, _ in tweets_dates_users:\n",
        "        if tweet_date in date_counts:\n",
        "            date_counts[tweet_date] += 1\n",
        "        else:\n",
        "            date_counts[tweet_date] = 1\n",
        "    most_common_dates = sorted(date_counts.items(), key=lambda x: x[1],\n",
        "                               reverse=True)[:10]\n",
        "\n",
        "    # Paso 3: Obtención del usuario más activo para cada fecha más común\n",
        "    most_common_users = []\n",
        "    for date, _ in most_common_dates:\n",
        "        user_counts = {}\n",
        "        for tweet_date, username in tweets_dates_users:\n",
        "            if tweet_date == date:\n",
        "                if username in user_counts:\n",
        "                    user_counts[username] += 1\n",
        "                else:\n",
        "                    user_counts[username] = 1\n",
        "        most_common_user = max(user_counts, key=user_counts.get)\n",
        "        most_common_users.append(most_common_user)\n",
        "\n",
        "    # Paso 4: Formateo de las fechas y agrupación con los usuarios\n",
        "    result = [(datetime.strptime(date[0], \"%Y-%m-%d\").date(), user)\n",
        "                for date, user in zip(most_common_dates, most_common_users)]\n",
        "\n",
        "    # Paso 5: Retorno de resultados\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGZFq36DWItj"
      },
      "source": [
        "## - Pruebas y Ejecución de la función `q1_time`\n",
        "\n",
        "De acuerdo a la documentación, para medir el tiempo de ejecución se recomienda el uso de [py-spy](https://github.com/benfred/py-spy) o [Python Profilers](https://docs.python.org/3/library/profile.html) sin embargo el uso de estas herramientas para una sola función lo considero engorroso ya que solo requiero medir el tiempo que tarda en ejecutarse la funcion `q1_time`.\n",
        "\n",
        "***1. Medición de tiempo:***\n",
        "\n",
        "Dada la explicación anterior, para la medición del tiempo de ejecución de `q1_time` solamente utilizo la función `time` nativa de Phyton para tomar un tiempo de inicio antes de la ejecución de la función y un tiempo final una vez culmina su ejecución luego calculo la diferencia entre ambos y obtengo la medición de tiempo requerida.\n",
        "\n",
        "***2. Ejecución de q1_time:***\n",
        "\n",
        "Se realiza la ejecición de de `q1_time` con `test_file_path` como argumento (base de datos) y se imprime su resultado.\n",
        "\n",
        "***3. Impresión de resultado \"Humanizado\":***\n",
        "\n",
        "Se imprime el mismo resultado anterior organizando la información para que resulta más facil de comprender."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rE-3wYvWKFt",
        "outputId": "3f40fe57-7b96-41e0-9358-1a50a3d1349d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tiempo de ejecución de q1_time: 9.109431982040405 s \n",
            "\n",
            "Resultados obtenidos:\n",
            "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')] \n",
            "\n",
            "Resultados humanizados:\n",
            "1. Fecha: 2021-02-12, Usuario con más publicaciones: RanbirS00614606\n",
            "2. Fecha: 2021-02-13, Usuario con más publicaciones: MaanDee08215437\n",
            "3. Fecha: 2021-02-17, Usuario con más publicaciones: RaaJVinderkaur\n",
            "4. Fecha: 2021-02-16, Usuario con más publicaciones: jot__b\n",
            "5. Fecha: 2021-02-14, Usuario con más publicaciones: rebelpacifist\n",
            "6. Fecha: 2021-02-18, Usuario con más publicaciones: neetuanjle_nitu\n",
            "7. Fecha: 2021-02-15, Usuario con más publicaciones: jot__b\n",
            "8. Fecha: 2021-02-20, Usuario con más publicaciones: MangalJ23056160\n",
            "9. Fecha: 2021-02-23, Usuario con más publicaciones: Surrypuria\n",
            "10. Fecha: 2021-02-19, Usuario con más publicaciones: Preetm91\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Medir el tiempo de ejecución de q1_time\n",
        "start_time = time.time()\n",
        "results = q1_time(test_file_path)\n",
        "end_time = time.time()\n",
        "# Calcular el tiempo de ejecución\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Tiempo de ejecución de q1_time: {execution_time} s \\n\")\n",
        "\n",
        "# Imprimir los resultados obtenidos\n",
        "print(\"Resultados obtenidos:\")\n",
        "print(results, \"\\n\")\n",
        "\n",
        "print(\"Resultados humanizados:\")\n",
        "for i, (date, username) in enumerate(results, start=1):\n",
        "    print(f\"{i}. Fecha: {date}, Usuario con más publicaciones: {username}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***Conclusión*** `q1_time`\n",
        "\n",
        "Luego de muchas pruebas se opta por seleccionar el metodo que no hace uso de librerias ni funciones adicionales para la implementación de `q1_time` ya que arroja tiempos más bajos en los conteos de fechas y usarios que con otras implementaciones que usan clases como `Counter` y `defaultdict`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbtWtuyVOoly"
      },
      "source": [
        "# **R#1 - Enfoque 2:** Optimización de la memoria en uso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iWsKwkoIwKu"
      },
      "source": [
        "### ***- Primer intento:*** función `q1_memory`\n",
        "\n",
        "La función `q1_memory` procesa un archivo JSON que contiene registros de tweets y devuelve las 10 fechas más comunes junto con el usuario más activo para cada fecha.\n",
        "\n",
        "En este primer intento no voy a usar librerias adicionales, utilizo simplemente un diccionario estándar `dates_dict` de Python para ir recolectando fechas y usuarios junto con el método `setdefault()`.\n",
        "\n",
        "La función `q1_memory_attemp_1` procesa un archivo JSON que contiene registros de tweets y devuelve las 10 fechas más comunes junto con el usuario más activo para cada fecha.\n",
        "\n",
        "***Descripción detallada:***\n",
        "\n",
        "***1.   Inicialización del diccionario de fechas y usuarios:***\n",
        "*   Se crea un diccionario llamado `dates_dict` para almacenar los pares de fecha-usuario y contar la cantidad de tweets por usuario en cada fecha.\n",
        "\n",
        "***2.   Procesamiento de los datos:***\n",
        "*   Se abre el archivo especificado en `file_path` en modo de lectura y se procesa línea por línea.\n",
        "*   Para cada línea, se carga el JSON y se extraen la fecha y el nombre de usuario del tweet.\n",
        "*   Se actualiza el contador de tweets por usuario y fecha en el diccionario `dates_dict`.\n",
        "\n",
        "***3.   Ordenamiento de las fechas según la cantidad total de tweets:***\n",
        "*   Se obtienen las fechas más comunes ordenando el diccionario `dates_dict` según la suma de los valores (número de tweets) de cada fecha.\n",
        "\n",
        "***4.   Obtención del usuario más activo por fecha:***\n",
        "*   Para cada fecha más común, se obtiene el usuario más activo (el que más tweets ha realizado) utilizando el método `max`.\n",
        "\n",
        "***5.   Formateo de las fechas:***\n",
        "*   Las fechas extraídas inicialmente están en formato de cadena de texto. Se utilizan para crear objetos `datetime.date` utilizando la función `datetime.strptime()` para convertirlas al formato deseado.\n",
        "\n",
        "***6.   Retorno de resultados:***\n",
        "*   La función devuelve una lista de tuplas, donde cada tupla contiene una fecha y el usuario más activo para esa fecha.\n",
        "\n",
        "Esta implementación proporciona una manera eficiente de analizar datos de tweets y obtener información sobre las fechas y usuarios más activos en la plataforma.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "T0Ytj0VsIwKu"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q1_memory_attempt_1(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "    \"\"\"\n",
        "    Esta función procesa un archivo JSON que contiene registros de tweets y devuelve las 10 fechas más comunes junto con el usuario más activo para cada fecha.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): La ruta del archivo JSON que contiene los registros de tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[datetime.date, str]]: Una lista de tuplas, donde cada tupla contiene una fecha y el usuario más activo para esa fecha.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si el archivo especificado en file_path no se encuentra.\n",
        "    \"\"\"\n",
        "    # Paso 1: Inicialización del diccionario de fechas y usuarios\n",
        "    dates_dict = {}\n",
        "\n",
        "    # Paso 2: Procesamiento de los datos\n",
        "    with open(file_path, 'r') as data:\n",
        "        for line_data in data:\n",
        "            tweet = json.loads(line_data)\n",
        "            tweet_date = tweet['date'].split('T')[0]\n",
        "            username = tweet['user']['username']\n",
        "\n",
        "            # Paso 3: Actualización del contador de tweets por usuario y fecha\n",
        "            if tweet_date not in dates_dict:\n",
        "                dates_dict[tweet_date] = {}\n",
        "\n",
        "            dates_dict[tweet_date].setdefault(username, 0)\n",
        "            dates_dict[tweet_date][username] += 1\n",
        "\n",
        "    # Paso 4: Ordenamiento de las fechas según la cantidad total de tweets\n",
        "    top_dates = sorted(dates_dict.keys(), key=lambda x: sum(dates_dict[x].values()), reverse=True)[:10]\n",
        "\n",
        "    # Paso 5: Obtención del usuario más activo por fecha\n",
        "    top_users = [max(dates_dict[date], key=dates_dict[date].get) for date in top_dates]\n",
        "\n",
        "    # Paso 6: Formateo de las fechas\n",
        "    top_dates = [datetime.strptime(date_str, \"%Y-%m-%d\").date() for date_str in top_dates]\n",
        "\n",
        "    # Paso 7: Retorno de resultados\n",
        "    return list(zip(top_dates, top_users))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmhboTaN5_Le"
      },
      "source": [
        "### ***- Segundo intento:*** función `q1_memory`\n",
        "\n",
        "En este otro intento, se proporciona una manera eficiente de analizar datos de tweets y obtener información sobre las fechas y usuarios más activos en la plataforma.\n",
        "\n",
        "La gran diferencia con el anterior es que al realizar la lectura del archivo, los datos se almacenan en una lista donde cada elemento es otra lista que contiene la fecha del tweet y el nombre de usuario del autor.\n",
        "\n",
        "***Descripción detallada:***\n",
        "\n",
        "***1.   Lectura del archivo JSON:***\n",
        "*   La función comienza abriendo el archivo JSON especificado en el parámetro `file_path` en modo de lectura.\n",
        "*   Lee línea por línea del archivo y carga los datos en un diccionario donde cada clave es la fecha del tweet y el valor es otro diccionario que almacena los usuarios y sus respectivos conteos de tweets.\n",
        "\n",
        "***2.   Procesamiento de los datos:***\n",
        "*   Para cada línea en el archivo, se extrae la fecha del tweet y el nombre de usuario del autor.\n",
        "*   Se actualiza el contador de tweets por usuario y fecha en el diccionario utilizando `setdefault()`.\n",
        "\n",
        "***3.   Determinación de las fechas más comunes:***\n",
        "*   Las fechas se ordenan según el número total de tweets publicados en cada una de ellas, utilizando `sorted()` y una función `key`.\n",
        "\n",
        "***4.   Obtención del usuario más activo por fecha:***\n",
        "*   Para cada una de las fechas más comunes, se determina el usuario más activo encontrando el usuario con el mayor número de tweets para esa fecha en particular.\n",
        "\n",
        "***5.   Formateo de las fechas:***\n",
        "*   Las fechas extraídas inicialmente están en formato de cadena de texto.\n",
        "*   Se utilizan para crear objetos `datetime.date` utilizando la función `datetime.strptime()` para convertirlas al formato deseado.\n",
        "\n",
        "***6.   Agrupación de las fechas y usuarios:***\n",
        "*   Se combinan las fechas formateadas y los usuarios más activos en una lista de tuplas.\n",
        "*   Cada tupla contiene una fecha y el usuario más activo para esa fecha.\n",
        "\n",
        "***7.   Retorno de resultados:***\n",
        "*   La función devuelve la lista de tuplas que contiene las 10 fechas principales con los usuarios más activos para cada una de esas fechas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "43tUMrfd6AH9"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q1_memory_attempt_2(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "    \"\"\"\n",
        "    Esta función procesa un archivo JSON que contiene registros de tweets y devuelve las 10 fechas más comunes junto con el usuario más activo para cada fecha.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): La ruta del archivo JSON que contiene los registros de tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[datetime.date, str]]: Una lista de tuplas, donde cada tupla contiene una fecha y el usuario más activo para esa fecha.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si el archivo especificado en file_path no se encuentra.\n",
        "    \"\"\"\n",
        "    # Paso 1: Inicialización del diccionario de fechas y usuarios\n",
        "    dates_dict = {}\n",
        "\n",
        "    # Paso 2: Procesamiento de los datos\n",
        "    with open(file_path, 'r') as data:\n",
        "        tweets_dates_users = [[json.loads(line)['date'].split('T')[0], json.loads(line)['user']['username']] for line in data.readlines()]\n",
        "\n",
        "    for tweet_date, username in tweets_dates_users:\n",
        "        # Paso 3: Actualización del contador de tweets por usuario y fecha\n",
        "        if tweet_date not in dates_dict:\n",
        "            dates_dict[tweet_date] = {}\n",
        "        dates_dict[tweet_date][username] = dates_dict[tweet_date].get(username, 0) + 1\n",
        "\n",
        "    # Paso 4: Ordenamiento de las fechas según la cantidad total de tweets\n",
        "    top_dates = sorted(dates_dict.keys(), key=lambda x: sum(dates_dict[x].values()), reverse=True)[:10]\n",
        "\n",
        "    # Paso 5: Obtención del usuario más activo por fecha\n",
        "    top_users = [max(dates_dict[date], key=dates_dict[date].get) for date in top_dates]\n",
        "\n",
        "    # Paso 6: Formateo de las fechas\n",
        "    top_dates = [datetime.strptime(date_str, \"%Y-%m-%d\").date() for date_str in top_dates]\n",
        "\n",
        "    # Paso 7: Retorno de resultados\n",
        "    return list(zip(top_dates, top_users))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKn1y7d4fy68"
      },
      "source": [
        "### ***- Intento definitivo:*** función `q1_memory`\n",
        "\n",
        "Luego de intentar con los diccionarios estándar de Python, la solución más obvia a este problema es usar la clase `defaultdict` que se encuentra en el módulo `collections` de Python. Funciona de manera similar a un diccionario convencional (dict), pero con una diferencia clave: automáticamente crea valores por defecto para claves que aún no están en el diccionario. Esto significa que no es necesario preocuparse por verificar si una clave existe antes de acceder a ella o asignarle un valor.\n",
        "\n",
        "En esta implementación también se lee el archivo linea por linea para mejorar el uso de memoria y no cargar todo el archivo json en memoria.\n",
        "\n",
        "\n",
        "***Descripción detallada:***\n",
        "\n",
        "***1.   Lectura del archivo JSON:***\n",
        "*   La función comienza abriendo el archivo JSON especificado en el parámetro `file_path` en modo de lectura.\n",
        "*   Luego lee todas las líneas del archivo y carga los datos en una lista de listas.\n",
        "*   Cada sublista contiene la fecha del tweet y el nombre de usuario del autor del tweet.\n",
        "*   Estos datos se extraen del JSON utilizando la función `json.loads(line)['date'].split('T')[0]` para obtener la fecha y `json.loads(line)['user']['username']` para obtener el nombre de usuario.\n",
        "\n",
        "***2.   Procesamiento de los datos:***\n",
        "*   Se utiliza un diccionario para almacenar los pares fecha - usuario y sus respectivos conteos de tweets.\n",
        "*   Para cada tweet en el archivo, se extrae la fecha y el nombre de usuario.\n",
        "*   Luego, se actualiza el contador de tweets por usuario y fecha en el diccionario.\n",
        "\n",
        "***3.   Determinación de las fechas más comunes:***\n",
        "*   Utilizando `sorted()` y `key`, se determinan las 10 fechas más comunes en el diccionario.\n",
        "*   Las fechas se ordenan según el número total de tweets publicados en cada una de ellas.\n",
        "\n",
        "***4.   Obtención del usuario más activo por fecha:***\n",
        "*   Para cada una de las fechas más comunes, se determina el usuario más activo.\n",
        "*   Esto se logra encontrando el usuario con el mayor número de tweets para esa fecha en particular.\n",
        "\n",
        "***5.   Formateo de las fechas:***\n",
        "*   Las fechas extraídas inicialmente están en formato de cadena de texto.\n",
        "*   Se utilizan para crear objetos datetime.date utilizando la función `datetime.strptime()` para convertirlas al formato deseado.\n",
        "\n",
        "***6.   Agrupación de las fechas y usuarios:***\n",
        "*   Finalmente, se combinan las fechas formateadas y los usuarios más activos en una lista de tuplas.\n",
        "*   Cada tupla contiene una fecha y el usuario más activo para esa fecha.\n",
        "\n",
        "***7.   Retorno de resultados:***\n",
        "*   La función devuelve la lista de tuplas que contiene las 10 fechas principales con los usuarios más activos para cada una de esas fechas.\n",
        "*   Esta función proporciona una manera eficiente de analizar datos de tweets y obtener información sobre las fechas y usuarios más activos en la plataforma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "hxAfh6zZcmRM"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "from datetime import datetime\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "    \"\"\"\n",
        "    Esta función analiza un archivo JSON que contiene registros de tweets y devuelve las 10 fechas\n",
        "    más comunes junto con el usuario más activo para cada fecha.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): La ruta del archivo JSON que contiene los registros de tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[datetime.date, str]]: Una lista de tuplas, donde cada tupla contiene una fecha\n",
        "        y el usuario más activo para esa fecha.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si no se encuentra el archivo especificado en file_path.\n",
        "    \"\"\"\n",
        "\n",
        "    # Paso 1: Lectura del archivo JSON\n",
        "    dates_dict = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    # Paso 2: Procesamiento de los datos\n",
        "    with open(file_path, 'r') as data:\n",
        "        for line_data in data:\n",
        "            tweet = json.loads(line_data)\n",
        "            tweet_date = tweet['date'].split('T')[0]\n",
        "            username = tweet['user']['username']\n",
        "\n",
        "            # Actualización del contador de tweets por usuario y fecha\n",
        "            dates_dict[tweet_date][username] += 1\n",
        "\n",
        "    # Paso 3: Determinación de las fechas más comunes\n",
        "    top_dates = sorted(dates_dict.keys(), key=lambda x: sum(dates_dict[x].values()), reverse=True)[:10]\n",
        "\n",
        "    # Paso 4: Obtención del usuario más activo por fecha\n",
        "    top_users = [max(dates_dict[date], key=dates_dict[date].get) for date in top_dates]\n",
        "\n",
        "    # Paso 5: Formateo de las fechas\n",
        "    top_dates = [datetime.strptime(date_str, \"%Y-%m-%d\").date() for date_str in top_dates]\n",
        "\n",
        "    # Paso 6: Agrupación de las fechas y usuarios\n",
        "    result = list(zip(top_dates, top_users))\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2i790-lIwKv"
      },
      "source": [
        "## - Ejecuto la función `q1_memory`\n",
        "\n",
        "***Medición de memoria:***\n",
        "\n",
        "Utilizando memory_profiler para medir el uso de memoria de la función `q1_memory`. `memory_usage` devuelve una lista que contiene el uso de memoria en diferentes puntos de la ejecución de la función. En este caso, se pasa `(q1_memory, (test_file_path,))` como argumento a `memory_usage`, lo que significa que estás midiendo el uso de memoria de `q1_memory` con `test_file_path` como argumento (base de datos). Finalmente se imprime el usuo de memoria de `q1_memory`.\n",
        "\n",
        "***2. Ejecución de q1_memory:***\n",
        "\n",
        "Se realiza la ejecición de de `q1_memory` con `test_file_path` como argumento (base de datos) y se imprime su resultado.\n",
        "\n",
        "***3. Impresión de resultado \"Humanizado\":***\n",
        "\n",
        "Se imprime el mismo resultado anterior organizando la información para que resulta más facil de comprender.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_NA0pJjIwKv",
        "outputId": "ff50fdcc-7fca-45e0-9511-6dc503bfe0b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uso de memoria de q1_memory: 313.60546875 MB \n",
            "\n",
            "Resultados obtenidos:\n",
            "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')] \n",
            "\n",
            "Resultados humanizados:\n",
            "1. Fecha: 2021-02-12, Usuario con más publicaciones: RanbirS00614606\n",
            "2. Fecha: 2021-02-13, Usuario con más publicaciones: MaanDee08215437\n",
            "3. Fecha: 2021-02-17, Usuario con más publicaciones: RaaJVinderkaur\n",
            "4. Fecha: 2021-02-16, Usuario con más publicaciones: jot__b\n",
            "5. Fecha: 2021-02-14, Usuario con más publicaciones: rebelpacifist\n",
            "6. Fecha: 2021-02-18, Usuario con más publicaciones: neetuanjle_nitu\n",
            "7. Fecha: 2021-02-15, Usuario con más publicaciones: jot__b\n",
            "8. Fecha: 2021-02-20, Usuario con más publicaciones: MangalJ23056160\n",
            "9. Fecha: 2021-02-23, Usuario con más publicaciones: Surrypuria\n",
            "10. Fecha: 2021-02-19, Usuario con más publicaciones: Preetm91\n"
          ]
        }
      ],
      "source": [
        "import memory_profiler\n",
        "\n",
        "# Medir el uso de memoria de q1_memory con memory-profiler\n",
        "mem_usage = memory_profiler.memory_usage((q1_memory, (test_file_path, )))\n",
        "\n",
        "# Imprimir el uso de memoria\n",
        "print(f\"Uso de memoria de q1_memory: {max(mem_usage)} MB \\n\")\n",
        "\n",
        "# Ejecutar q1_memory y obtener los resultados\n",
        "results = q1_memory(test_file_path)\n",
        "\n",
        "# Imprimir los resultados obtenidos\n",
        "print(\"Resultados obtenidos:\")\n",
        "print(results, \"\\n\")\n",
        "\n",
        "print(\"Resultados humanizados:\")\n",
        "for i, (date, username) in enumerate(results, start=1):\n",
        "    print(f\"{i}. Fecha: {date}, Usuario con más publicaciones: {username}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6siYtj2LrlBh"
      },
      "source": [
        "### ***Conclusión*** `q1_memory`\n",
        "Luego de todas las pruebas, para este punto en el que se prioriza el uso de memoria, se opta por dejar la implementación de la función `q1_memory` en la que se realiza la implementación de `defaultdict` y la lectura del JSON linea por linea, ya que es la que mejores resultados arroja."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TbN1IrdlDHe"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6POLMQ5nmask"
      },
      "source": [
        "# **Reto #2**\n",
        "\n",
        "Los top 10 emojis más usados con su respectivo conteo. Debe incluir las siguientes funciones:\n",
        "```python\n",
        "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
        "```\n",
        "```python\n",
        "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
        "```\n",
        "```python\n",
        "Returns:\n",
        "[(\"✈️\", 6856), (\"❤️\", 5876), ...]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldU8ixnLYz8O"
      },
      "source": [
        "# **R#2 - Enfoque 1:** Optimización del tiempo de ejecución."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MOX7I3KY1Kn"
      },
      "source": [
        "### ***- Primer intento:*** función `q2_time_attempt_1`\n",
        "\n",
        "En este intento lo que hago es buscar los emojis mapeando los caracteres y usando un diccionario estándar para contar la frecuencia de cada emoji. Aca se utiliza el método `json.load(f)` para cargar todos los tweets del archivo JSON en una lista de diccionarios.\n",
        "\n",
        "\n",
        "\n",
        "#### Descripción detallada:\n",
        "\n",
        "1. **Inicialización del diccionario de conteo de emojis:**\n",
        "   - Se crea un diccionario vacío llamado `emoji_counts` para almacenar la frecuencia de cada emoji.\n",
        "\n",
        "2. **Lectura del archivo JSON y procesamiento de los tweets:**\n",
        "   - Se abre el archivo JSON especificado en modo de lectura.\n",
        "   - Se leen todos los tweets de una vez y se almacenan en la lista `tweets`.\n",
        "   \n",
        "3. **Obtención del contenido de los tweets en un gran string:**\n",
        "   - Se inicializa una cadena vacía llamada `tweets_content` para almacenar el contenido de todos los tweets.\n",
        "   - Se itera sobre cada tweet en la lista `tweets`, se carga el contenido del tweet como un diccionario JSON y se agrega el contenido al string `tweets_content`.\n",
        "\n",
        "4. **Búsqueda de emojis en el gran string:**\n",
        "   - Se recorre cada caracter del string `tweets_content` y se verifica si es un emoji válido utilizando la función `map(chr, range(128, 1024))`.\n",
        "   - Los emojis válidos encontrados se agregan a la lista `all_emojis`.\n",
        "   \n",
        "5. **Conteo de la frecuencia de cada emoji:**\n",
        "   - Se itera sobre cada emoji en la lista `all_emojis`.\n",
        "   - Se actualiza el diccionario `emoji_counts` con la frecuencia de cada emoji.\n",
        "   \n",
        "6. **Obtención de los 10 emojis más utilizados:**\n",
        "   - Se ordena el diccionario `emoji_counts` según el valor de frecuencia de los emojis en orden descendente.\n",
        "   - Se seleccionan los 10 emojis más utilizados y se devuelven en una lista de tuplas.\n",
        "\n",
        "7. **Retorno de resultados:**\n",
        "   - La función devuelve una lista de tuplas que contiene los 10 emojis más utilizados junto con su respectivo conteo de ocurrencias.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Xl7dAXaWM30j"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q2_time_attempt_1(file_path: str) -> List[Tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Encuentra los 10 emojis más utilizados en los tweets presentes en el archivo JSON especificado,\n",
        "    junto con su respectivo conteo de ocurrencias.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Ruta al archivo JSON que contiene los datos de los tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, int]]: Una lista de tuplas que contiene los 10 emojis más utilizados, cada una con su respectivo conteo de ocurrencias.\n",
        "    \"\"\"\n",
        "    # Paso 1: Inicialización de un diccionario para contar la frecuencia de cada emoji\n",
        "    emoji_counts = {}\n",
        "\n",
        "    # Paso 2: Lectura del archivo JSON y procesamiento de los tweets\n",
        "    with open(file_path, 'r') as data:\n",
        "        # Paso 3: Se obtienen todos los objetos de tweets de una vez\n",
        "        tweets = data.readlines()\n",
        "\n",
        "    # Paso 4: Se obtiene un gran string que contiene todos los contenidos de los tweets\n",
        "    tweets_content = \"\"\n",
        "    for tweet in tweets:\n",
        "        tweets_content += json.loads(tweet)['content']\n",
        "\n",
        "    # Paso 5: Obtención de todos los emojis presentes en el gran string\n",
        "    all_emojis = [char for char in tweets_content if char in ' '.join(map(chr, range(128, 1024)))]\n",
        "\n",
        "    # Paso 6: Conteo de la frecuencia de cada emoji y actualización del diccionario de conteo\n",
        "    for emoji in all_emojis:\n",
        "        emoji_counts[emoji] = emoji_counts.get(emoji, 0) + 1\n",
        "\n",
        "    # Paso 7: Obtención de los 10 emojis más utilizados con su respectivo conteo\n",
        "    top_10_emojis = sorted(emoji_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "    return top_10_emojis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGTHu8T0ZHwA"
      },
      "source": [
        "### ***- Segundo intento:*** función `q2_time`\n",
        "\n",
        "A diferencia de la implementación anterior, en donde busco los emojis comparando si están dentro del rango de códigos Unicode que representan emojis lo cual se prueba que es muy ineficiente, ahora en este intento utilizo la función `emoji_list` de la librería `emoji` para obtener los emojis presentes en el contenido de cada tweet, manteniendo el resto de la funcionalidad intacta.\n",
        "\n",
        "\n",
        "#### Descripción detallada:\n",
        "\n",
        "***1.   Inicialización del contador de emojis:***\n",
        "*   Se inicializa un diccionario vacío `emoji_counts` para contar la frecuencia de cada emoji encontrado en los tweets.\n",
        "\n",
        "***2.   Lectura del archivo JSON:***\n",
        "*   Se lee el archivo JSON especificado en el parámetro `file_path` y se almacenan todos los objetos de tweets de una vez en la lista `tweets`.\n",
        "\n",
        "***3.   Concatenación de los contenidos de los tweets:***\n",
        "*   Se recorren todos los tweets en la lista `tweets` y se concatenan sus contenidos en un solo gran string `tweets_content`.\n",
        "\n",
        "***4.   Obtención de los emojis presentes en los tweets:***\n",
        "*   Utilizando la función `emoji_list` se obtienen los emojis presentes en el gran string `tweets_content`. La función `emoji_list` devuelve una lista de diccionarios, donde cada diccionario contiene información sobre un emoji, incluyendo su representación Unicode.\n",
        "*   `[emoji['emoji'] for emoji in emoji_list(tweets_content)]` Utiliza una list comprehension para extraer solo la representación Unicode de cada emoji de la lista de diccionarios devuelta por `emoji_list`, y almacena estas representaciones en la lista `emojis_in_tweets`. Esto asegura que solo se obtenga la representación Unicode de cada emoji y no se incluyan otros detalles del diccionario.\n",
        "\n",
        "***5.   Actualización del contador de emojis:***\n",
        "*   Se recorren todos los emojis presentes en la lista `emojis_in_tweets` y se actualiza el contador de emojis `emoji_counts` con la frecuencia de cada emoji.\n",
        "\n",
        "***6.   Obtención de los 10 emojis más utilizados:***\n",
        "*   Se ordena el diccionario `emoji_counts` por sus valores en orden descendente para obtener los emojis más utilizados.\n",
        "*   Se seleccionan los primeros 10 elementos del diccionario ordenado para obtener los 10 emojis más utilizados junto con su respectivo conteo de ocurrencias.\n",
        "\n",
        "***7.   Retorno de resultados:***\n",
        "*   La función devuelve una lista de tuplas que contiene los 10 emojis más utilizados, donde cada tupla tiene la forma `(emoji, conteo)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "TWQcP26bZORA"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from emoji import emoji_list\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q2_time_attempt_2(file_path: str) -> List[Tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Encuentra los 10 emojis más utilizados en los tweets presentes en el archivo JSON especificado,\n",
        "    junto con su respectivo conteo de ocurrencias.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Ruta al archivo JSON que contiene los datos de los tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, int]]: Una lista de tuplas que contiene los 10 emojis más utilizados, cada una con su respectivo conteo de ocurrencias.\n",
        "    \"\"\"\n",
        "    # Paso 1: Se inicializa un diccionario para contar la frecuencia de cada emoji\n",
        "    emoji_counts = {}\n",
        "\n",
        "    # Paso 2: Se obtienen todos los objetos de tweets de una vez\n",
        "    with open(file_path, 'r') as data:\n",
        "        tweets = data.readlines()\n",
        "\n",
        "    # Paso 3: Se obtiene un gran string que contiene todos los contenidos de los tweets\n",
        "    tweets_content = \"\"\n",
        "    for tweet in tweets:\n",
        "        tweets_content += json.loads(tweet)['content']\n",
        "\n",
        "    # Paso 4: Se obtienen los emojis presentes en el gran string utilizando emoji_list\n",
        "    emojis_in_tweets = [emoji['emoji'] for emoji in emoji_list(tweets_content)]\n",
        "\n",
        "    # Paso 5: Se actualiza el contador de emojis con la frecuencia de cada emoji\n",
        "    for emoji in emojis_in_tweets:\n",
        "        emoji_counts[emoji] = emoji_counts.get(emoji, 0) + 1\n",
        "\n",
        "    # Paso 6: Se obtienen los 10 emojis más utilizados con su respectivo conteo\n",
        "    top_10_emojis = sorted(emoji_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "    return top_10_emojis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jMlwueFeDeh"
      },
      "source": [
        "### ***- Intento definitivo:*** función `q2_time`\n",
        "\n",
        "\n",
        "En esta versión final, se utiliza la clase `Counter`, que es una clase en Python que se encuentra en el módulo `collections` y que me permite contar la ocurrencia de elementos en una secuencia y generar un diccionario con las frecuencias de esos elementos para contar la ocurrencia de emojis.\n",
        "\n",
        "En lugar de iterar manualmente sobre los tweets y acumular los emojis, se utiliza un enfoque más eficiente. El uso de Counter simplifica significativamente el proceso y mejora la eficiencia del código en términos de legibilidad y rendimiento.\n",
        "\n",
        "\n",
        "#### Detalles de la Implementación\n",
        "\n",
        "1. **Inicialización del contador de emojis:**\n",
        "   Se inicializa un objeto `Counter` para contar la frecuencia de cada emoji en los tweets.\n",
        "\n",
        "2. **Lectura del archivo JSON y procesamiento de los tweets:**\n",
        "   Se abre el archivo JSON especificado en modo de lectura y se recorren todas las líneas.\n",
        "   Para cada línea, se carga el contenido del tweet como un diccionario JSON y se extraen los emojis presentes en el contenido del tweet.\n",
        "\n",
        "3. **Obtención de los emojis de cada línea:**\n",
        "   Se utiliza la función `emoji_list` para obtener una lista de emojis presentes en el contenido del tweet.\n",
        "\n",
        "4. **Actualización del contador de emojis:**\n",
        "   Se actualiza el contador de emojis utilizando el método `update` del objeto `Counter` con la lista de emojis obtenida en el paso anterior.\n",
        "\n",
        "5. **Devolución de los 10 emojis más utilizados:**\n",
        "   Se devuelve una lista con los 10 emojis más utilizados junto con sus respectivos conteos de ocurrencias, utilizando el método `most_common` del objeto `Counter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "2-iOaoWqeEhf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "from emoji import emoji_list\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q2_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "    \"\"\"\n",
        "    Esta función procesa un archivo JSON que contiene registros de tweets y devuelve los 10 emojis más utilizados,\n",
        "    junto con su respectivo conteo de ocurrencias.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): La ruta del archivo JSON que contiene los datos de los tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, int]]: Una lista de tuplas que contiene los 10 emojis más utilizados,\n",
        "        cada una con su respectivo conteo de ocurrencias.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si el archivo especificado en file_path no se encuentra.\n",
        "    \"\"\"\n",
        "\n",
        "    # Paso 1: Inicialización del contador de emojis\n",
        "    emoji_counter = Counter()\n",
        "\n",
        "    # Paso 2: Lectura del archivo JSON y procesamiento de los tweets\n",
        "    with open(file_path, 'r') as data:\n",
        "        for line in data:\n",
        "            tweet_content = json.loads(line)['content']\n",
        "\n",
        "            # Paso 3: Obtención de los emojis de cada línea\n",
        "            tweet_emojis = [emoji['emoji'] for emoji in emoji_list(tweet_content)]\n",
        "\n",
        "            # Paso 4: Actualización del contador de emojis\n",
        "            emoji_counter.update(tweet_emojis)\n",
        "\n",
        "    # Paso 5: Devolución de los 10 emojis más utilizados\n",
        "    return emoji_counter.most_common(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnaHHxHhddA3"
      },
      "source": [
        "## - Ejecución de la función `q2_time`\n",
        "\n",
        "Al igual que en el primer reto, solo se utiliza la libreria `time` para la medición del tiempo que tarda en ejecutarse la funcion `q2_time`.\n",
        "\n",
        "***1. Medición de tiempo:***\n",
        "\n",
        "Dada la explicación anterior, para la medición del tiempo de ejecución de `q2_time` solamente utilizo la función `time` nativa de Phyton para tomar un tiempo de inicio antes de la ejecución de la función y un tiempo final una vez culmina su ejecución luego calculo la diferencia entre ambos y obtengo la medición de tiempo requerida.\n",
        "\n",
        "***2. Ejecución de q2_time:***\n",
        "\n",
        "Se realiza la ejecición de de `q2_time` con `test_file_path` como argumento (base de datos) y se imprime su resultado.\n",
        "\n",
        "***3. Impresión de resultado \"Humanizado\":***\n",
        "\n",
        "Se imprime el mismo resultado anterior organizando la información para que resulta más facil de comprender."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47gWyUHpdw4Q",
        "outputId": "f7040143-377f-4ad8-dd99-de38ae67cc80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tiempo de ejecución de q2_time: 44.589800119400024 s \n",
            "\n",
            "Resultados obtenidos:\n",
            "[('🙏', 5049), ('😂', 3072), ('🚜', 2972), ('🌾', 2182), ('🇮🇳', 2086), ('🤣', 1668), ('✊', 1651), ('❤️', 1382), ('🙏🏻', 1317), ('💚', 1040)] \n",
            "\n",
            "Resultados humanizados:\n",
            "1. Fecha: 🙏, Usuario con más publicaciones: 5049\n",
            "2. Fecha: 😂, Usuario con más publicaciones: 3072\n",
            "3. Fecha: 🚜, Usuario con más publicaciones: 2972\n",
            "4. Fecha: 🌾, Usuario con más publicaciones: 2182\n",
            "5. Fecha: 🇮🇳, Usuario con más publicaciones: 2086\n",
            "6. Fecha: 🤣, Usuario con más publicaciones: 1668\n",
            "7. Fecha: ✊, Usuario con más publicaciones: 1651\n",
            "8. Fecha: ❤️, Usuario con más publicaciones: 1382\n",
            "9. Fecha: 🙏🏻, Usuario con más publicaciones: 1317\n",
            "10. Fecha: 💚, Usuario con más publicaciones: 1040\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Medir el tiempo de ejecución de q2_time\n",
        "start_time = time.time()\n",
        "results = q2_time(test_file_path)\n",
        "end_time = time.time()\n",
        "# Calcular el tiempo de ejecución\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Tiempo de ejecución de q2_time: {execution_time} s \\n\")\n",
        "\n",
        "# Imprimir los resultados obtenidos\n",
        "print(\"Resultados obtenidos:\")\n",
        "print(results, \"\\n\")\n",
        "\n",
        "print(\"Resultados humanizados:\")\n",
        "for i, (date, username) in enumerate(results, start=1):\n",
        "    print(f\"{i}. Fecha: {date}, Usuario con más publicaciones: {username}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovhtScTi4qIf"
      },
      "source": [
        "### ***Conclusión*** `q2_time`\n",
        "\n",
        "Los intentos 1 y 2 se intentaron hacer utilizando el minimo de funciones adicionales, en el primero de ellos usando representación Unicode de cada emoji para hacer la búsqueda y en el segundo usando `emoji_list()`, pero al revisar su ejecución y los resultados que se obtienen no son satisfactorios, puesto que muchos Unicodes los malinterpreta y el proceso de búsqueda es muy lento.\n",
        "\n",
        "En la versión final se utilizan `Counter` y `emoji_list` de manera que se crea una manera simple y eficiente de hacer la búsqueda y conteo de los emojis sobre la base de datos y después de todos los intentos se obtiene en esta implementación el mejor tiempo de respuesta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8UVf3akuORo"
      },
      "source": [
        "# **R#2 - Enfoque 2:** Optimización de la memoria en uso.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap92_Ya_uWog"
      },
      "source": [
        "### ***- Primer intento:*** función `q2_memory`\n",
        "\n",
        "En este primer intento se toma el primer intento realizado en `q2_time`, pero para optimizar el uso de memoria en esta función se procesa cada tweet línea por línea directamente desde el archivo, evitando cargar todo el contenido del archivo en memoria.\n",
        "\n",
        "En este intento, procesamos cada línea del archivo directamente en el bucle `for line in data`. Esto reduce la carga de memoria al no necesitar almacenar todas las líneas en una lista antes de procesarlas.\n",
        "\n",
        "\n",
        "#### Descripción detallada:\n",
        "\n",
        "1. **Inicialización del diccionario de conteo de emojis:**\n",
        "   - Se crea un diccionario vacío llamado `emoji_counts` para almacenar la frecuencia de cada emoji.\n",
        "\n",
        "2. **Lectura del archivo JSON y procesamiento de los tweets:**\n",
        "   - Se abre el archivo JSON especificado en modo de lectura.\n",
        "   - Se leen todos los tweets de una vez y se almacenan en la lista `tweets`.\n",
        "   \n",
        "3. **Obtención del contenido de los tweets en un gran string:**\n",
        "   - Se inicializa una cadena vacía llamada `tweets_content` para almacenar el contenido de todos los tweets.\n",
        "   - Se itera sobre cada tweet en la lista `tweets`, se carga el contenido del tweet como un diccionario JSON y se agrega el contenido al string `tweets_content`.\n",
        "\n",
        "4. **Búsqueda de emojis en el gran string:**\n",
        "   - Se recorre cada caracter del string `tweets_content` y se verifica si es un emoji válido utilizando la función `map(chr, range(128, 1024))`.\n",
        "   - Los emojis válidos encontrados se agregan a la lista `all_emojis`.\n",
        "   \n",
        "5. **Conteo de la frecuencia de cada emoji:**\n",
        "   - Se itera sobre cada emoji en la lista `all_emojis`.\n",
        "   - Se actualiza el diccionario `emoji_counts` con la frecuencia de cada emoji.\n",
        "   \n",
        "6. **Obtención de los 10 emojis más utilizados:**\n",
        "   - Se ordena el diccionario `emoji_counts` según el valor de frecuencia de los emojis en orden descendente.\n",
        "   - Se seleccionan los 10 emojis más utilizados y se devuelven en una lista de tuplas.\n",
        "\n",
        "7. **Retorno de resultados:**\n",
        "   - La función devuelve una lista de tuplas que contiene los 10 emojis más utilizados junto con su respectivo conteo de ocurrencias.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "kKnEdv13ucX1"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q2_memory_attempt_1(file_path: str) -> List[Tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Encuentra los 10 emojis más utilizados en los tweets presentes en el archivo JSON especificado,\n",
        "    junto con su respectivo conteo de ocurrencias.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Ruta al archivo JSON que contiene los datos de los tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, int]]: Una lista de tuplas que contiene los 10 emojis más utilizados, cada una con su respectivo conteo de ocurrencias.\n",
        "    \"\"\"\n",
        "    # Paso 1: Inicialización de un diccionario para contar la frecuencia de cada emoji\n",
        "    emoji_counts = {}\n",
        "\n",
        "    # Paso 2: Lectura del archivo JSON y procesamiento de los tweets línea por línea\n",
        "    with open(file_path, 'r') as data:\n",
        "        for line in data:\n",
        "            # Paso 3: Cargar el contenido del tweet como un diccionario\n",
        "            tweet = json.loads(line)\n",
        "\n",
        "            # Paso 4: Obtener los emojis presentes en el contenido del tweet\n",
        "            tweet_content = tweet['content']\n",
        "            emojis_in_tweet = [char for char in tweet_content if char in ' '.join(map(chr, range(128, 1024)))]\n",
        "\n",
        "            # Paso 5: Actualización del contador de emojis con la frecuencia de cada emoji en el tweet\n",
        "            for emoji in emojis_in_tweet:\n",
        "                emoji_counts[emoji] = emoji_counts.get(emoji, 0) + 1\n",
        "\n",
        "    # Paso 6: Obtención de los 10 emojis más utilizados con su respectivo conteo\n",
        "    top_10_emojis = sorted(emoji_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "    return top_10_emojis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y0wvHk26cRD"
      },
      "source": [
        "### ***- Segundo intento:*** función `q2_memory`\n",
        "\n",
        "En este intento de `q2_memory` tomo como base el correspondiente intento de `q2_time` en donde utilizo `emoji_list()` para hacer la búsqueda de los emojis y se hace la lectura del archivo JSON y procesamiento de los tweets línea por línea para optimizar el manejo de memoria.\n",
        "\n",
        "\n",
        "#### Descripción detallada:\n",
        "\n",
        "1. **Inicialización del diccionario de conteo de emojis:**\n",
        "   - Se crea un diccionario vacío llamado `emoji_counts` para almacenar la frecuencia de cada emoji.\n",
        "\n",
        "2. **Lectura del archivo JSON y procesamiento de los tweets línea por línea:**\n",
        "   - Se abre el archivo JSON especificado en modo de lectura.\n",
        "   - Se itera sobre cada línea del archivo para procesar cada tweet individualmente.\n",
        "\n",
        "3. **Cargar el contenido del tweet como un diccionario:**\n",
        "   - Se carga el contenido del tweet como un diccionario JSON utilizando la función `json.loads()`.\n",
        "\n",
        "4. **Obtención de los emojis presentes en el contenido del tweet:**\n",
        "   - Se extrae el contenido del tweet y se obtienen los emojis presentes en él utilizando la función `emoji_list()` del módulo `emoji`.\n",
        "   - Los emojis se almacenan en una lista llamada `emojis_in_tweet`.\n",
        "\n",
        "5. **Actualización del contador de emojis con la frecuencia de cada emoji en el tweet:**\n",
        "   - Se itera sobre cada emoji en la lista `emojis_in_tweet`.\n",
        "   - Se actualiza el diccionario `emoji_counts` con la frecuencia de cada emoji.\n",
        "\n",
        "6. **Obtención de los 10 emojis más utilizados:**\n",
        "   - Se ordena el diccionario `emoji_counts` según el valor de frecuencia de los emojis en orden descendente.\n",
        "   - Se seleccionan los 10 emojis más utilizados y se devuelven en una lista de tuplas.\n",
        "\n",
        "Este intento utiliza la función `emoji_list()` del módulo `emoji` para obtener los emojis presentes en el contenido de cada tweet, sin la necesidad de usar ninguna librería adicional.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "0MJhu3M36dFT"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import List, Tuple\n",
        "from emoji import emoji_list\n",
        "\n",
        "def q2_memory_attempt_2(file_path: str) -> List[Tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Encuentra los 10 emojis más utilizados en los tweets presentes en el archivo JSON especificado,\n",
        "    junto con su respectivo conteo de ocurrencias.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Ruta al archivo JSON que contiene los datos de los tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, int]]: Una lista de tuplas que contiene los 10 emojis más utilizados, cada una con su respectivo conteo de ocurrencias.\n",
        "    \"\"\"\n",
        "    # Paso 1: Inicialización de un diccionario para contar la frecuencia de cada emoji\n",
        "    emoji_counts = {}\n",
        "\n",
        "    # Paso 2: Lectura del archivo JSON y procesamiento de los tweets línea por línea\n",
        "    with open(file_path, 'r') as data:\n",
        "        for line in data:\n",
        "            # Paso 3: Cargar el contenido del tweet como un diccionario\n",
        "            tweet = json.loads(line)\n",
        "\n",
        "            # Paso 4: Obtener los emojis presentes en el contenido del tweet\n",
        "            tweet_content = tweet['content']\n",
        "            emojis_in_tweet = [emoji['emoji'] for emoji in emoji_list(tweet_content)]\n",
        "\n",
        "            # Paso 5: Actualización del contador de emojis con la frecuencia de cada emoji en el tweet\n",
        "            for emoji in emojis_in_tweet:\n",
        "                emoji_counts[emoji] = emoji_counts.get(emoji, 0) + 1\n",
        "\n",
        "    # Paso 6: Obtención de los 10 emojis más utilizados con su respectivo conteo\n",
        "    top_10_emojis = sorted(emoji_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "    return top_10_emojis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2Y8d73b8LGP"
      },
      "source": [
        "### ***- Intento definitivo:*** función `q2_memory`\n",
        "\n",
        "Este enfoque garantiza un procesamiento eficiente del archivo JSON al hacerlo linea por linea garantizando menor consumo de memoria y permite encontrar rápidamente los emojis más utilizados en los tweets.\n",
        "\n",
        "\n",
        "#### Detalles de la implementación:\n",
        "\n",
        "1. **Inicialización del contador de emojis:**\n",
        "   - Se utiliza la clase `Counter` del módulo `collections` para inicializar un contador que almacenará el conteo de ocurrencias de cada emoji.\n",
        "\n",
        "2. **Lectura del archivo JSON y procesamiento de los tweets:**\n",
        "   - Se utiliza la función `open()` para abrir el archivo JSON en modo de lectura.\n",
        "   - Se utiliza un loop `for` para iterar sobre cada línea del archivo JSON.\n",
        "   - Se utiliza la función `json.loads()` para cargar cada línea como un objeto JSON y acceder al contenido del tweet.\n",
        "\n",
        "3. **Obtención de los emojis de cada línea:**\n",
        "   - Se utiliza la función `emoji_list()` del módulo `emoji` para obtener una lista de emojis presentes en el contenido del tweet.\n",
        "\n",
        "4. **Actualización del contador de emojis:**\n",
        "   - Se utiliza una lista de comprensión para obtener los emojis de cada línea del tweet.\n",
        "   - Se utiliza el método `update()` del objeto `Counter` para actualizar el contador con los emojis obtenidos.\n",
        "\n",
        "5. **Devolución de los 10 emojis más utilizados:**\n",
        "   - Se utiliza el método `most_common(10)` del objeto `Counter` para obtener los 10 emojis más utilizados junto con su respectivo conteo de ocurrencias.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "njS67x2I8MgX"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "from emoji import emoji_list\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Esta función procesa un archivo JSON que contiene registros de tweets y devuelve los 10 emojis más utilizados,\n",
        "    junto con su respectivo conteo de ocurrencias.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): La ruta del archivo JSON que contiene los datos de los tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, int]]: Una lista de tuplas que contiene los 10 emojis más utilizados,\n",
        "        cada una con su respectivo conteo de ocurrencias.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si el archivo especificado en file_path no se encuentra.\n",
        "    \"\"\"\n",
        "\n",
        "    # Paso 1: Inicialización del contador de emojis\n",
        "    emoji_counter = Counter()\n",
        "\n",
        "    # Paso 2: Lectura del archivo JSON y procesamiento de los tweets\n",
        "    with open(file_path, 'r') as data:\n",
        "        for line in data:\n",
        "            tweet_content = json.loads(line)['content']\n",
        "\n",
        "            # Paso 3: Obtención de los emojis de cada línea\n",
        "            tweet_emojis = [emoji['emoji'] for emoji in emoji_list(tweet_content)]\n",
        "\n",
        "            # Paso 4: Actualización del contador de emojis\n",
        "            emoji_counter.update(tweet_emojis)\n",
        "\n",
        "    # Paso 5: Devolución de los 10 emojis más utilizados\n",
        "    return emoji_counter.most_common(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgLoZeCK8Nqw"
      },
      "source": [
        "## - Ejecución de la función `q2_memory`\n",
        "\n",
        "***Medición de memoria:***\n",
        "\n",
        "Utilizando memory_profiler para medir el uso de memoria de la función `q2_memory`. `memory_usage` devuelve una lista que contiene el uso de memoria en diferentes puntos de la ejecución de la función. En este caso, se pasa `(q2_memory, (test_file_path,))` como argumento a `memory_usage`, lo que significa que estás midiendo el uso de memoria de `q2_memory` con `test_file_path` como argumento (base de datos). Finalmente se imprime el usuo de memoria de `q2_memory`.\n",
        "\n",
        "***2. Ejecución de q2_memory:***\n",
        "\n",
        "Se realiza la ejecición de de `q2_memory` con `test_file_path` como argumento (base de datos) y se imprime su resultado.\n",
        "\n",
        "***3. Impresión de resultado \"Humanizado\":***\n",
        "\n",
        "Se imprime el mismo resultado anterior organizando la información para que resulta más facil de comprender."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX7GRMiY8O6a",
        "outputId": "6a231a07-f4b7-4640-8e90-ef3562934c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uso de memoria de q1_memory: 279.41015625 MB \n",
            "\n",
            "Resultados obtenidos:\n",
            "[('🙏', 5049), ('😂', 3072), ('🚜', 2972), ('🌾', 2182), ('🇮🇳', 2086), ('🤣', 1668), ('✊', 1651), ('❤️', 1382), ('🙏🏻', 1317), ('💚', 1040)] \n",
            "\n",
            "Resultados humanizados:\n",
            "1. Fecha: 🙏, Usuario con más publicaciones: 5049\n",
            "2. Fecha: 😂, Usuario con más publicaciones: 3072\n",
            "3. Fecha: 🚜, Usuario con más publicaciones: 2972\n",
            "4. Fecha: 🌾, Usuario con más publicaciones: 2182\n",
            "5. Fecha: 🇮🇳, Usuario con más publicaciones: 2086\n",
            "6. Fecha: 🤣, Usuario con más publicaciones: 1668\n",
            "7. Fecha: ✊, Usuario con más publicaciones: 1651\n",
            "8. Fecha: ❤️, Usuario con más publicaciones: 1382\n",
            "9. Fecha: 🙏🏻, Usuario con más publicaciones: 1317\n",
            "10. Fecha: 💚, Usuario con más publicaciones: 1040\n"
          ]
        }
      ],
      "source": [
        "import memory_profiler\n",
        "\n",
        "# Medir el uso de memoria de q1_memory con memory-profiler\n",
        "mem_usage = memory_profiler.memory_usage((q2_memory, (test_file_path, )))\n",
        "\n",
        "# Imprimir el uso de memoria\n",
        "print(f\"Uso de memoria de q1_memory: {max(mem_usage)} MB \\n\")\n",
        "\n",
        "# Ejecutar q1_memory y obtener los resultados\n",
        "results = q2_memory(test_file_path)\n",
        "\n",
        "# Imprimir los resultados obtenidos\n",
        "print(\"Resultados obtenidos:\")\n",
        "print(results, \"\\n\")\n",
        "\n",
        "print(\"Resultados humanizados:\")\n",
        "for i, (date, username) in enumerate(results, start=1):\n",
        "    print(f\"{i}. Fecha: {date}, Usuario con más publicaciones: {username}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90_ffQDT8Pr8"
      },
      "source": [
        "### ***Conclusión*** `q2_memory`\n",
        "\n",
        "Semejante que con q2_time, los intentos 1 y 2 se intentaron hacer utilizando el minimo de funciones adicionales, en el primero de ellos usando representación Unicode de cada emoji para hacer la búsqueda y en el segundo usando `emoji_list()`, pero al revisar su ejecución y los resultados que se obtienen no son satisfactorios, puesto que muchos Unicodes los malinterpreta y el proceso de búsqueda es muy lento.\n",
        "\n",
        "En la versión final se utilizan `Counter`, `emoji_list()`, junto con un recorrido linea a linea del archivo para evitar la sobrecarga en memoria de información y asi, de esta manera se crea una manera simple y eficiente de hacer la búsqueda y conteo de los emojis sobre la base de datos y después de todos los intentos se obtiene en esta implementación el mejor tiempo de respuesta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISAfardNlAO4"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VAVfvS3mnwk"
      },
      "source": [
        "# **Reto R#3**\n",
        "\n",
        "\n",
        "El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos. Debe incluir las siguientes funciones:\n",
        "```python\n",
        "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
        "```\n",
        "```python\n",
        "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
        "```\n",
        "```python\n",
        "Returns:\n",
        "[(\"LATAM321\", 387), (\"LATAM_CHI\", 129), ...]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoUk68zRux87"
      },
      "source": [
        "# **R#3 - Enfoque 1:** Optimización del tiempo de ejecución."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTdAasdcB3i-"
      },
      "source": [
        "### ***- Primer intento:*** función `q3_time`\n",
        "\n",
        "En este primer intento de implementar la función `q3_time`, proceso el archivo JSON  y devuelve los 10 nombres de usuario más mencionados junto con su frecuencia de menciones.\n",
        "\n",
        "\n",
        "#### Descripción detallada:\n",
        "\n",
        "1. **Lectura del archivo JSON:**\n",
        "   - Se abre el archivo especificado en `file_path` en modo de lectura (`'r'`) utilizando el contexto `with`.\n",
        "   - Se intenta parsear las líneas JSON utilizando la biblioteca `json`, extrayendo las listas de usuarios mencionados en cada tweet.\n",
        "   \n",
        "2. **Procesamiento de los datos extraídos:**\n",
        "   - Se inicializa una lista vacía llamada `usernames` para almacenar los nombres de usuario mencionados en los tweets.\n",
        "   - Se itera sobre cada lista de usuarios mencionados en los tweets extraídos.\n",
        "   - Si la lista de usuarios no es `None`, se extraen los nombres de usuario de cada usuario y se agregan a la lista `usernames`.\n",
        "\n",
        "3. **Conteo de menciones de usuario:**\n",
        "   - Utilizando la clase `Counter` de la biblioteca estándar `collections`, se cuenta la frecuencia de cada nombre de usuario en la lista `usernames`.\n",
        "   - Se obtienen los 10 nombres de usuario más comunes utilizando el método `most_common(10)` de `Counter`.\n",
        "\n",
        "4. **Retorno de resultados:**\n",
        "   - La función devuelve una lista de tuplas que contiene los 10 nombres de usuario más mencionados junto con su respectiva frecuencia de menciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Gp2fXyP9B5Cz"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q3_time_attempt_1(file_path: str) -> List[Tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Esta función procesa un archivo JSON que potencialmente puede contener tweets mal formados y devuelve los 10 nombres de usuario más mencionados junto con su frecuencia de menciones.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Ruta al archivo JSON que contiene los datos de los tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, int]]: Una lista de tuplas que contiene los 10 nombres de usuario más mencionados junto con su respectiva frecuencia de menciones.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si el archivo especificado en file_path no se encuentra.\n",
        "    \"\"\"\n",
        "\n",
        "    # Paso 1: Lectura del archivo JSON y extracción de las listas de usuarios mencionados en los tweets\n",
        "    with open(file_path, 'r') as data:\n",
        "        try:\n",
        "            # Se intenta hacer el parsing de las líneas JSON utilizando la biblioteca 'json'\n",
        "            tweet_mentioned_users = [json.loads(line)['mentionedUsers'] for line in data.readlines()]\n",
        "        except (json.JSONDecodeError, KeyError) as e:\n",
        "            # Manejar posibles errores de análisis de JSON o la clave faltante de 'mentionedUsers'\n",
        "            print(f\"Error parsing linea: {e}\")\n",
        "            tweet_mentioned_users = []\n",
        "\n",
        "    # Paso 2: Procesamiento de los datos extraídos para obtener los nombres de usuario mencionados\n",
        "    usernames = []\n",
        "    for user_list in tweet_mentioned_users:\n",
        "        if user_list is not None:\n",
        "            # Se extraen los nombres de usuario de cada lista de usuarios mencionados\n",
        "            usernames.extend([user[\"username\"] for user in user_list])\n",
        "\n",
        "    # Paso 3: Conteo de menciones de usuario y obtención de los 10 más comunes\n",
        "    user_mentions = Counter(usernames).most_common(10)\n",
        "\n",
        "    return list(user_mentions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4ps8yrjOTNS"
      },
      "source": [
        "### ***- Segundo intento:*** función `q3_time`\n",
        "\n",
        "En este intento utilizo una lectura linea a linea del JSON y verifico si tiene información de user antes de realizar el conteo con la ayuda de `Counter`.\n",
        "\n",
        "#### Detalles de la implementación:\n",
        "\n",
        "1. **Lectura del archivo JSON y extracción de los usuarios mencionados en los tweets:**\n",
        "   - Se abre el archivo JSON especificado en modo de lectura.\n",
        "   - Para cada línea del archivo JSON, se intenta cargar el tweet como un objeto JSON.\n",
        "   - Si el tweet contiene información de usuario (`user`) y dicho usuario no es nulo, se extrae el nombre de usuario (`username`) y se agrega a la lista `mentioned_users`.\n",
        "\n",
        "2. **Conteo de menciones de usuario y obtención de los 10 más comunes:**\n",
        "   - Se utiliza la clase `Counter` para contar la frecuencia de cada nombre de usuario en la lista `mentioned_users`.\n",
        "   - Se obtienen los 10 nombres de usuario más mencionados junto con su respectiva frecuencia de menciones utilizando el método `most_common(10)` de la clase `Counter`.\n",
        "\n",
        "En caso de que ocurra un error durante la decodificación del JSON (por ejemplo, si hay líneas mal formateadas), se maneja adecuadamente y se continúa con el procesamiento de las líneas restantes del archivo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "IRRul0zROUaT"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q3_time_attempt_2(file_path: str) -> List[Tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Esta función procesa un archivo JSON que contiene tweets y devuelve los 10 nombres de usuario\n",
        "    más mencionados junto con su frecuencia de menciones.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Ruta al archivo JSON que contiene los datos de los tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, int]]: Una lista de tuplas que contiene los 10 nombres de usuario más mencionados junto con su respectiva frecuencia de menciones.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si el archivo especificado en file_path no se encuentra.\n",
        "    \"\"\"\n",
        "    # Paso 1: Lectura del archivo JSON y extracción de los usuarios mencionados en los tweets\n",
        "    with open(file_path, 'r') as data:\n",
        "        mentioned_users = []\n",
        "\n",
        "        # Procesar cada línea del archivo JSON\n",
        "        for line in data:\n",
        "            tweet = json.loads(line)\n",
        "            if 'user' in tweet and tweet['user'] is not None and 'username' in tweet['user']:\n",
        "                mentioned_users.append(tweet['user']['username'])\n",
        "\n",
        "    # Paso 2: Conteo de menciones de usuario y obtención de los 10 más comunes\n",
        "    user_mentions = Counter(mentioned_users).most_common(10)\n",
        "\n",
        "    return user_mentions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlwWhOZ1vEa0"
      },
      "source": [
        "### ***- Intento definitivo:*** función `q3_time`\n",
        "\n",
        "\n",
        "En esta versión final, se utilizan `list comprehensions` para iterar de manera eficiente tanto en la lectura del JSON como en la obtención del usuario teniendo especial cuidado con las listas vacias.\n",
        "\n",
        " Finalmente se hace uso de la clase `Counter` de la libreria `collections` para obtener los 10 nombres de usuario más mencionados junto con su respectiva frecuencia de menciones.\n",
        "\n",
        " El resultado es una función muy corta pero eficiente para iterar y encontrar los usuarios más mencionados en base de datos.\n",
        "\n",
        "\n",
        "#### Detalles de la implementación:\n",
        "\n",
        "1. **Obtención de las listas de usuarios mencionados en cada tweet:**\n",
        "   - Se utiliza la función `open()` para abrir el archivo JSON especificado en modo de lectura. Esto devuelve un objeto de archivo.\n",
        "   - Se utiliza la función `readlines()` para leer cada línea del archivo y almacenarlas en una lista.\n",
        "   - Se utiliza una `list comprehension` para iterar sobre cada línea del archivo JSON.\n",
        "   - Se utiliza la función `json.loads()` para analizar cada línea como un objeto JSON.\n",
        "   - Se accede al atributo `'mentionedUsers'` de cada tweet para obtener la lista de usuarios mencionados en ese tweet.\n",
        "\n",
        "2. **Obtención del nombre de usuario de cada usuario en las listas de menciones:**\n",
        "   - Nuevamente se usa una `list comprehension` para iterar sobre cada objeto en la lista de menciones de usuarios obtenida en el paso anterior.\n",
        "   - Se utiliza la función `append()` para agregar el nombre de usuario (`'username'`) de cada objeto a la lista `usernames`.\n",
        "   - Se utiliza una condición para filtrar las listas vacías de menciones (caso None) y evitar errores al intentar acceder al nombre de usuario.\n",
        "\n",
        "3. **Obtención de los 10 nombres de usuario más comunes:**\n",
        "   - Se utiliza la clase `Counter` del módulo `collections` para contar la frecuencia de cada nombre de usuario en la lista `usernames`.\n",
        "   - Se utiliza el método `most_common(10)` de la clase `Counter` para obtener los 10 nombres de usuario más mencionados junto con su respectiva frecuencia de menciones.\n",
        "   - Este método devuelve una lista de tuplas, donde cada tupla contiene el nombre de usuario y el recuento de menciones, ordenados por frecuencia de menciones de mayor a menor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "-ANAv7-rmlCu"
      },
      "outputs": [],
      "source": [
        "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Esta función procesa un archivo JSON que contiene registros de tweets y devuelve los 10 nombres de usuario\n",
        "    más mencionados en los tweets, junto con la frecuencia de menciones de cada uno.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Ruta al archivo JSON que contiene los datos de los tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, int]]: Una lista de tuplas que contiene los 10 nombres de usuario más mencionados,\n",
        "        junto con la frecuencia de menciones de cada uno.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si el archivo especificado en file_path no se encuentra.\n",
        "    \"\"\"\n",
        "    # Paso 1: Se obtienen las listas de usuarios mencionados en cada tweet\n",
        "    with open(file_path, 'r') as data:\n",
        "        tweet_mentioned_users = [json.loads(line)['mentionedUsers'] for line in data.readlines()]\n",
        "\n",
        "    # Paso 2: Se obtiene el username de cada user dentro de cada lista de mentionedUsers, exceptuando las listas vacías (caso None).\n",
        "    usernames = [user['username'] for obj in tweet_mentioned_users if obj is not None for user in obj]\n",
        "\n",
        "    # Paso 3: Se retornan los 10 usernames más comunes usando la clase Counter para contar y ordenar.\n",
        "    return Counter(usernames).most_common(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY-ValeOBOp3"
      },
      "source": [
        "## - Pruebas y Ejecución de la función `q3_time`\n",
        "\n",
        "Al igual que en el primer reto, solo se utiliza la libreria `time` para la medición del tiempo que tarda en ejecutarse la funcion `q3_time`.\n",
        "\n",
        "***1. Medición de tiempo:***\n",
        "\n",
        "Dada la explicación anterior, para la medición del tiempo de ejecución de `q3_time` solamente utilizo la función `time` nativa de Phyton para tomar un tiempo de inicio antes de la ejecución de la función y un tiempo final una vez culmina su ejecución luego calculo la diferencia entre ambos y obtengo la medición de tiempo requerida.\n",
        "\n",
        "***2. Ejecución de q2_time:***\n",
        "\n",
        "Se realiza la ejecición de de `q3_time` con `test_file_path` como argumento (base de datos) y se imprime su resultado.\n",
        "\n",
        "***3. Impresión de resultado \"Humanizado\":***\n",
        "\n",
        "Se imprime el mismo resultado anterior organizando la información para que resulta más facil de comprender."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt9I2SMKBSaE",
        "outputId": "a6683810-0ae0-4150-9364-2371273d301d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tiempo de ejecución de q3_time: 10.538569927215576 s \n",
            "\n",
            "Resultados obtenidos:\n",
            "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)] \n",
            "\n",
            "Resultados humanizados:\n",
            "1. Fecha: narendramodi, Usuario con más publicaciones: 2265\n",
            "2. Fecha: Kisanektamorcha, Usuario con más publicaciones: 1840\n",
            "3. Fecha: RakeshTikaitBKU, Usuario con más publicaciones: 1644\n",
            "4. Fecha: PMOIndia, Usuario con más publicaciones: 1427\n",
            "5. Fecha: RahulGandhi, Usuario con más publicaciones: 1146\n",
            "6. Fecha: GretaThunberg, Usuario con más publicaciones: 1048\n",
            "7. Fecha: RaviSinghKA, Usuario con más publicaciones: 1019\n",
            "8. Fecha: rihanna, Usuario con más publicaciones: 986\n",
            "9. Fecha: UNHumanRights, Usuario con más publicaciones: 962\n",
            "10. Fecha: meenaharris, Usuario con más publicaciones: 926\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Medir el tiempo de ejecución de q3_time\n",
        "start_time = time.time()\n",
        "results = q3_time(test_file_path)\n",
        "end_time = time.time()\n",
        "# Calcular el tiempo de ejecución\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Tiempo de ejecución de q3_time: {execution_time} s \\n\")\n",
        "\n",
        "# Imprimir los resultados obtenidos\n",
        "print(\"Resultados obtenidos:\")\n",
        "print(results, \"\\n\")\n",
        "\n",
        "print(\"Resultados humanizados:\")\n",
        "for i, (date, username) in enumerate(results, start=1):\n",
        "    print(f\"{i}. Fecha: {date}, Usuario con más publicaciones: {username}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw7SkPAL570S"
      },
      "source": [
        "### ***Conclusión*** `q3_time`\n",
        "\n",
        "\n",
        "Si bien el intento definitivo que obtuvo unos mejores tiempos en ejecución es similar al intento 1, este último se descartó debido a que en varias pruebas mostró unos tiempos más elevados de lo normal.\n",
        "\n",
        "El intento 2 no se tuvo en cuenta debido a que por la forma en la que se intento leer el JSON dejaba mucha información por fuera y su resultado final no era exacto, por ello este intento tiene los mejores tiempos de todos.\n",
        "\n",
        "Como lo mencioné, la función final `q3_time` resultó ser una función muy corta pero eficiente para iterar y encontrar los usuarios más mencionados en base de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhyzjTYxu4at"
      },
      "source": [
        "# **R#3 - Enfoque 2:** Optimización de la memoria en uso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLg7EWzeZhQi"
      },
      "source": [
        "### ***- Primer intento:*** función `q3_memory`\n",
        "\n",
        "En este intento la función `q3_memory` procesa el archivo línea por línea, lo que minimiza la cantidad de datos almacenados en memoria en un momento dado. Utiliza un contador (`user_mentions`) para mantener un seguimiento eficiente del conteo de menciones de cada usuario. Y no almacena explícitamente los tweets en la memoria, lo que reduce el uso de memoria durante el procesamiento.\n",
        "\n",
        "#### Detalles de la implementación:\n",
        "\n",
        "1. **Inicialización del contador de menciones**:\n",
        "    - Se inicializa un contador de menciones llamado `user_mentions` utilizando la clase `Counter` del módulo `collections`.\n",
        "\n",
        "2. **Lectura del archivo JSON y procesamiento de tweets**:\n",
        "    - Se abre el archivo JSON especificado en `file_path` en modo de lectura.\n",
        "    - Se itera sobre cada línea del archivo utilizando un bucle `for`.\n",
        "    \n",
        "3. **Obtención del nombre de usuario del tweet**:\n",
        "    - En cada iteración, se carga la línea como un objeto JSON utilizando `json.loads()`.\n",
        "    - Se extrae el nombre de usuario del tweet accediendo a la clave `'user'` y luego a la clave `'username'`.\n",
        "\n",
        "4. **Conteo de menciones (@) en el contenido del tweet**:\n",
        "    - Se cuenta el número de menciones (@) en el contenido del tweet utilizando el método `count()` de las cadenas de Python.\n",
        "\n",
        "5. **Actualización del contador de menciones para el usuario**:\n",
        "    - Se actualiza el contador `user_mentions` para el nombre de usuario actual sumando el número de menciones contadas en el paso anterior.\n",
        "\n",
        "6. **Obtención de los top 10 usuarios más influyentes**:\n",
        "    - Una vez que se han procesado todos los tweets, se utiliza el método `most_common()` de `Counter` para obtener los 10 usuarios más influyentes con su respectivo conteo de menciones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "dwY4ypqeEG61"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q3_memory_attempt_1(file_path: str) -> List[Tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Encuentra el top 10 histórico de usuarios más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos.\n",
        "\n",
        "    Args:\n",
        "    - file_path (str): Ruta al archivo JSON que contiene los datos de los tweets.\n",
        "\n",
        "    Returns:\n",
        "    - List[Tuple[str, int]]: Una lista de tuplas que contiene el top 10 de usuarios más influyentes, cada uno con su respectivo conteo de menciones.\n",
        "    \"\"\"\n",
        "    # Paso 1: Inicializar un contador para almacenar el conteo de menciones de cada usuario.\n",
        "    user_mentions = Counter()\n",
        "\n",
        "    # Paso 2: Leer el archivo JSON y procesar los tweets línea por línea.\n",
        "    with open(file_path, 'r') as data:\n",
        "        for line in data:\n",
        "            tweet = json.loads(line)\n",
        "\n",
        "            # Paso 3: Obtener el nombre de usuario del tweet.\n",
        "            username = tweet['user']['username']\n",
        "\n",
        "            # Paso 4: Contar las menciones (@) en el contenido del tweet.\n",
        "            mentions_count = tweet['content'].count('@')\n",
        "\n",
        "            # Paso 5: Actualizar el contador de menciones para el usuario.\n",
        "            user_mentions[username] += mentions_count\n",
        "\n",
        "    # Paso 6: Obtener los top 10 usuarios más influyentes con su respectivo conteo de menciones.\n",
        "    top_users = user_mentions.most_common(10)\n",
        "\n",
        "    return top_users"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWPAeIL1c-iS"
      },
      "source": [
        "### ***- Segundo intento:*** función `q3_memory`\n",
        "\n",
        "En esta versión final, la función `q3_memory` procesa un archivo JSON que contiene tweets para encontrar los 10 usuarios más influyentes basándose en el conteo de menciones (@) que registra cada uno de ellos.\n",
        "\n",
        "#### Detalles de la implementación:\n",
        "\n",
        "1. **Creación del objeto Counter para registrar los usernames:**\n",
        "   - Se utiliza la clase `Counter` del módulo `collections` para crear un contador que almacenará el conteo de menciones de cada usuario.\n",
        "\n",
        "2. **Lectura de cada línea del archivo:**\n",
        "   - Se utiliza un loop infinito para leer el archivo línea por línea.\n",
        "\n",
        "3. **Carga de la línea como un objeto JSON y obtención de la lista de usuarios mencionados:**\n",
        "   - Se utiliza la función `json.loads()` para cargar cada línea del archivo como un objeto JSON.\n",
        "   - Se accede al atributo `'mentionedUsers'` de cada tweet para obtener la lista de usuarios mencionados en ese tweet.\n",
        "\n",
        "4. **Verificación de si la lista de usuarios mencionados es None:**\n",
        "   - Se verifica si la lista de usuarios mencionados es `None` para evitar errores al intentar acceder a los usernames.\n",
        "\n",
        "5. **Obtención de los usernames de la lista de usuarios mencionados y actualización del contador:**\n",
        "   - Se utiliza una lista de comprensión para obtener los usernames de la lista de usuarios mencionados.\n",
        "   - Se utiliza el método `update()` del objeto `Counter` para actualizar el contador con los usernames obtenidos.\n",
        "\n",
        "6. **Retorno de los 10 usernames más mencionados:**\n",
        "   - Se utiliza el método `most_common(10)` del objeto `Counter` para obtener los 10 usernames más mencionados junto con su respectiva frecuencia de menciones.\n",
        "\n",
        "Este enfoque asegura una eficiente iteración a través del archivo JSON y permite encontrar rápidamente los usuarios más mencionados en base a su frecuencia de menciones.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ED144Ztxc_jf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q3_memory_attempt_2(file_path: str) -> List[Tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Encuentra el top 10 histórico de usuarios más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Ruta al archivo JSON que contiene los datos de los tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, int]]: Una lista de tuplas que contiene el top 10 de usuarios más influyentes, cada uno con su respectivo conteo de menciones.\n",
        "    \"\"\"\n",
        "    # Paso 1: Se crea el objeto Counter para registrar los usernames\n",
        "    users_counter = Counter()\n",
        "\n",
        "    # Se abre el archivo JSON en modo de lectura\n",
        "    with open(file_path, 'r') as data:\n",
        "        # Loop infinito para leer el archivo línea por línea\n",
        "        while True:\n",
        "            # Paso 2: Lectura de cada línea del archivo\n",
        "            line = data.readline()\n",
        "\n",
        "            # Condición de salida del loop while cuando se alcanza el final del archivo\n",
        "            if not line:\n",
        "                break\n",
        "\n",
        "            # Paso 3: Carga de la línea como un objeto JSON y obtención de la lista de usuarios mencionados\n",
        "            mentioned_users = json.loads(line)['mentionedUsers']\n",
        "\n",
        "            # Paso 4: Verificación de si la lista de usuarios mencionados es None\n",
        "            if mentioned_users is None:\n",
        "                continue\n",
        "\n",
        "            # Paso 5: Obtención de los usernames de la lista de usuarios mencionados y actualización del contador\n",
        "            usernames = [user['username'] for user in mentioned_users]\n",
        "            users_counter.update(usernames)\n",
        "\n",
        "    # Paso 6: Retorno de los 10 usernames más mencionados junto con su respectiva frecuencia de menciones\n",
        "    return users_counter.most_common(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Amo2RhEbkzDp"
      },
      "source": [
        "### ***- Intento definitivo:*** función `q3_memory`\n",
        "\n",
        "En este intento definitivo, la función `q3_memory` procesa el archivo línea por línea, lo que minimiza la cantidad de datos almacenados en memoria en un momento dado. Se utiliza un contador (`user_counter`) en lugar de almacenar todas las listas de usuarios mencionados, lo que reduce la cantidad de memoria utilizada. Y finalmente, se utiliza un generador para extraer los nombres de usuario de cada lista de usuarios mencionados, evitando así la creación de una lista temporal.\n",
        "\n",
        "\n",
        "#### Detalles de la implementación:\n",
        "\n",
        "1. **Procesamiento del archivo línea por línea**:\n",
        "    - Se inicializa un contador de usuarios `user_counter` utilizando la clase `Counter` del módulo `collections`.\n",
        "    - Se abre el archivo JSON especificado en `file_path` en modo de lectura.\n",
        "    - Se itera sobre cada línea del archivo utilizando un bucle `for`.\n",
        "    - En cada iteración, se carga la línea como un objeto JSON utilizando `json.loads()`.\n",
        "    - Se obtiene la lista de usuarios mencionados en el tweet utilizando el método `get()` para acceder a la clave `'mentionedUsers'` del objeto JSON.\n",
        "    - Si hay usuarios mencionados en el tweet, se actualiza el contador de usuarios utilizando el método `update()` de `Counter`, donde se pasa un generador que extrae los nombres de usuario de la lista de usuarios mencionados.\n",
        "\n",
        "2. **Obtención de los 10 usernames más comunes**:\n",
        "    - Una vez que se han procesado todas las líneas del archivo, se devuelve una lista de tuplas que contiene los 10 nombres de usuario más comunes y su frecuencia de menciones utilizando el método `most_common()` de `Counter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "mYMV0osIqac7"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Esta función procesa un archivo JSON que contiene registros de tweets y devuelve los 10 nombres de usuario\n",
        "    más mencionados en los tweets, junto con la frecuencia de menciones de cada uno.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Ruta al archivo JSON que contiene los datos de los tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, int]]: Una lista de tuplas que contiene los 10 nombres de usuario más mencionados,\n",
        "        junto con la frecuencia de menciones de cada uno.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si el archivo especificado en file_path no se encuentra.\n",
        "    \"\"\"\n",
        "    # Paso 1: Se procesa el archivo línea por línea\n",
        "    user_counter = Counter()\n",
        "\n",
        "    with open(file_path, 'r') as data:\n",
        "        for line in data:\n",
        "            tweet_data = json.loads(line)\n",
        "            mentioned_users = tweet_data.get('mentionedUsers')\n",
        "            if mentioned_users:\n",
        "                user_counter.update(user['username'] for user in mentioned_users)\n",
        "\n",
        "    # Paso 2: Se retornan los 10 usernames más comunes\n",
        "    return user_counter.most_common(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21VgbHQ1EL3j"
      },
      "source": [
        "## - Ejecución de la función `q3_memory`\n",
        "\n",
        "***Medición de memoria:***\n",
        "\n",
        "Utilizando memory_profiler para medir el uso de memoria de la función `q3_memory`. `memory_usage` devuelve una lista que contiene el uso de memoria en diferentes puntos de la ejecución de la función. En este caso, se pasa `(q3_memory, (test_file_path,))` como argumento a `memory_usage`, lo que significa que estás midiendo el uso de memoria de `q3_memory` con `test_file_path` como argumento (base de datos). Finalmente se imprime el usuo de memoria de `q3_memory`.\n",
        "\n",
        "***2. Ejecución de q3_memory:***\n",
        "\n",
        "Se realiza la ejecición de de `q3_memory` con `test_file_path` como argumento (base de datos) y se imprime su resultado.\n",
        "\n",
        "***3. Impresión de resultado \"Humanizado\":***\n",
        "\n",
        "Se imprime el mismo resultado anterior organizando la información para que resulta más facil de comprender."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LVetAICEkKX",
        "outputId": "381b14f1-42f1-49ed-95c4-e9b1e8524310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uso de memoria de q3_memory_attempt_1,: 335.60546875 MB \n",
            "\n",
            "Uso de memoria de q3_memory: 334.625 MB \n",
            "\n",
            "Resultados obtenidos:\n",
            "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)] \n",
            "\n",
            "Resultados humanizados:\n",
            "1. Fecha: narendramodi, Usuario con más publicaciones: 2265\n",
            "2. Fecha: Kisanektamorcha, Usuario con más publicaciones: 1840\n",
            "3. Fecha: RakeshTikaitBKU, Usuario con más publicaciones: 1644\n",
            "4. Fecha: PMOIndia, Usuario con más publicaciones: 1427\n",
            "5. Fecha: RahulGandhi, Usuario con más publicaciones: 1146\n",
            "6. Fecha: GretaThunberg, Usuario con más publicaciones: 1048\n",
            "7. Fecha: RaviSinghKA, Usuario con más publicaciones: 1019\n",
            "8. Fecha: rihanna, Usuario con más publicaciones: 986\n",
            "9. Fecha: UNHumanRights, Usuario con más publicaciones: 962\n",
            "10. Fecha: meenaharris, Usuario con más publicaciones: 926\n"
          ]
        }
      ],
      "source": [
        "import memory_profiler\n",
        "\n",
        "# Medir el uso de memoria de q3_memory_attempt_1, con memory-profiler\n",
        "mem_usage = memory_profiler.memory_usage((q3_memory_attempt_1, (test_file_path, )))\n",
        "\n",
        "# Imprimir el uso de memoria\n",
        "print(f\"Uso de memoria de q3_memory_attempt_1,: {max(mem_usage)} MB \\n\")\n",
        "\n",
        "# Medir el uso de memoria de q3_memory con memory-profiler\n",
        "mem_usage = memory_profiler.memory_usage((q3_memory, (test_file_path, )))\n",
        "\n",
        "# Imprimir el uso de memoria\n",
        "print(f\"Uso de memoria de q3_memory: {max(mem_usage)} MB \\n\")\n",
        "\n",
        "# Ejecutar q3_memory y obtener los resultados\n",
        "results = q3_memory(test_file_path)\n",
        "\n",
        "# Imprimir los resultados obtenidos\n",
        "print(\"Resultados obtenidos:\")\n",
        "print(results, \"\\n\")\n",
        "\n",
        "print(\"Resultados humanizados:\")\n",
        "for i, (date, username) in enumerate(results, start=1):\n",
        "    print(f\"{i}. Fecha: {date}, Usuario con más publicaciones: {username}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZRx3OWvk6xy"
      },
      "source": [
        "### ***Conclusión*** `q3_memory`\n",
        "\n",
        "Semejante que con q2_time, los intentos 1 y 2 se intentaron hacer utilizando el minimo de funciones adicionales, en el primero de ellos usando representación Unicode de cada emoji para hacer la búsqueda y en el segundo usando `emoji_list()`, pero al revisar su ejecución y los resultados que se obtienen no son satisfactorios, puesto que muchos Unicodes los malinterpreta y el proceso de búsqueda es muy lento.\n",
        "\n",
        "En la versión final se utilizan `Counter`, `emoji_list()`, junto con un recorrido linea a linea del archivo para evitar la sobrecarga en memoria de información y asi, de esta manera se crea una manera simple y eficiente de hacer la búsqueda y conteo de los emojis sobre la base de datos y después de todos los intentos se obtiene en esta implementación el mejor tiempo de respuesta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35r3Gq0uo8kT"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BUCgsdFpCli"
      },
      "source": [
        "# **Agradecimiento 🙏**\n",
        "\n",
        "Quiero expresar mi más sincero agradecimiento por brindarme la oportunidad de postularme al cargo de Data Engineer Challenge. Es un honor para mí tener la posibilidad de trabajar con un equipo tan talentoso y dinámico como el de LATAM. Estoy entusiasmado por la posibilidad de contribuir con mi experiencia y conocimientos, y espero poder colaborar pronto con ustedes para alcanzar metas compartidas y enfrentar desafíos emocionantes en el mundo de la ingeniería de datos. 😁\n",
        "\n",
        "Atentamente,\n",
        "\n",
        "Fabián Callejas\n",
        "`fabiancallejas@gmail.com`"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
