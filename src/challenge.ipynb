{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ0khVFTIwKp"
      },
      "source": [
        "# Data Engineer Challenge\n",
        "\n",
        "En este desafío, vamos a realizar un análisis de datos sobre un conjunto de tweets relacionados con las protestas de agricultores. Utilizaremos Python y algunas herramientas como para el desarrollo como `unittest`, `cProfile`, `memory_profiler` y `Jupyter Notebook` para llevar a cabo este análisis.\n",
        "\n",
        "## - Preparación del entorno\n",
        "\n",
        "A nivel local se crea un repositorio en gitHub entorno virtual que sirven para el inicio del desarrollo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6lGu9I9IwKt"
      },
      "source": [
        "## Instalación de los requerimientos:   \n",
        "\n",
        "Dentro del entorno virtual o el Jupyter Notebook se instalan los paquetes requeridos desde requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "e86ENRr_IwKt",
        "outputId": "eb0e443d-d371-4984-f8b2-9e9c6fb8dcfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji==2.10.1 (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 1))\n",
            "  Downloading emoji-2.10.1-py2.py3-none-any.whl (421 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting memory-profiler==0.61.0 (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 2))\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Collecting psutil==5.9.8 (from -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt (line 3))\n",
            "  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: psutil, emoji, memory-profiler\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "Successfully installed emoji-2.10.1 memory-profiler-0.61.0 psutil-5.9.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              },
              "id": "f08c5cb3ff4d40f0b9930c6c610f32db"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Instalar los paquetes desde requirements.txt\n",
        "!pip install -r https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxBk3q2NIwKu"
      },
      "source": [
        "Se cargan los datos desde JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "E9zY2YRFIwKu"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import io\n",
        "import requests\n",
        "\n",
        "# URL del archivo ZIP\n",
        "url = \"https://raw.githubusercontent.com/eLgRuNgE/challenge_DE/develop/data/tweets.json.zip\"\n",
        "\n",
        "# Descargar el archivo ZIP\n",
        "response = requests.get(url)\n",
        "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
        "\n",
        "# Obtengo el archivo requerido\n",
        "target_file_name = \"farmers-protest-tweets-2021-2-4.json\"\n",
        "zip_file.extract(target_file_name)\n",
        "\n",
        "# Ahora `target_file_name` está disponible en el directorio actual de Colab\n",
        "test_file_path = target_file_name"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reto Q1**\n",
        "\n",
        "Las top 10 fechas donde hay más tweets. Mencionar el usuario (username) que más publicaciones tiene por cada uno de esos días. Debe incluir las siguientes funciones:\n",
        "\n",
        "```python\n",
        "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "```\n",
        "```python\n",
        "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "```\n",
        "```python\n",
        "Returns:\n",
        "[(datetime.date(1999, 11, 15), \"LATAM321\"), (datetime.date(1999, 7, 15), \"LATAM_CHI\"), ...]\n",
        "```"
      ],
      "metadata": {
        "id": "eBpctVKKmPvI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q1 Enfoque 1:** Optimización del tiempo de ejecución."
      ],
      "metadata": {
        "id": "4K97hLzNMhBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***- Primer intento:*** función `q1_time`\n",
        "\n",
        "La solución más obvia a este problema es usar la clase `defaultdict` que se encuentra en el módulo `collections` de Python. Funciona de manera similar a un diccionario convencional (dict), pero con una diferencia clave: automáticamente crea valores por defecto para claves que aún no están en el diccionario. Esto significa que no es necesario preocuparse por verificar si una clave existe antes de acceder a ella o asignarle un valor.\n",
        "\n",
        "En esta implementación también se lee el archivo linea por linea para mejorar el uso de memoria y no cargar todo el archivo json en memoria.\n",
        "\n",
        "\n",
        "***Descripción detallada:***\n",
        "\n",
        "***1.   Lectura del archivo JSON:***\n",
        "*   La función comienza abriendo el archivo JSON especificado en el parámetro `file_path` en modo de lectura.\n",
        "*   Luego lee todas las líneas del archivo y carga los datos en una lista de listas.\n",
        "*   Cada sublista contiene la fecha del tweet y el nombre de usuario del autor del tweet.\n",
        "*   Estos datos se extraen del JSON utilizando la función `json.loads(line)['date'].split('T')[0]` para obtener la fecha y `json.loads(line)['user']['username']` para obtener el nombre de usuario.\n",
        "\n",
        "***2.   Procesamiento de los datos:***\n",
        "*   Se utiliza un diccionario para almacenar los pares fecha - usuario y sus respectivos conteos de tweets.\n",
        "*   Para cada tweet en el archivo, se extrae la fecha y el nombre de usuario.\n",
        "*   Luego, se actualiza el contador de tweets por usuario y fecha en el diccionario.\n",
        "\n",
        "***3.   Determinación de las fechas más comunes:***\n",
        "*   Utilizando `sorted()` y `key`, se determinan las 10 fechas más comunes en el diccionario.\n",
        "*   Las fechas se ordenan según el número total de tweets publicados en cada una de ellas.\n",
        "\n",
        "***4.   Obtención del usuario más activo por fecha:***\n",
        "*   Para cada una de las fechas más comunes, se determina el usuario más activo.\n",
        "*   Esto se logra encontrando el usuario con el mayor número de tweets para esa fecha en particular.\n",
        "\n",
        "***5.   Formateo de las fechas:***\n",
        "*   Las fechas extraídas inicialmente están en formato de cadena de texto.\n",
        "*   Se utilizan para crear objetos datetime.date utilizando la función `datetime.strptime()` para convertirlas al formato deseado.\n",
        "\n",
        "***6.   Agrupación de las fechas y usuarios:***\n",
        "*   Finalmente, se combinan las fechas formateadas y los usuarios más activos en una lista de tuplas.\n",
        "*   Cada tupla contiene una fecha y el usuario más activo para esa fecha.\n",
        "\n",
        "***7.   Retorno de resultados:***\n",
        "*   La función devuelve la lista de tuplas que contiene las 10 fechas principales con los usuarios más activos para cada una de esas fechas.\n",
        "*   Esta función proporciona una manera eficiente de analizar datos de tweets y obtener información sobre las fechas y usuarios más activos en la plataforma."
      ],
      "metadata": {
        "id": "FWrqdxWQMtUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "from datetime import datetime\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q1_time_attempt_1(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "    \"\"\"\n",
        "    Esta función analiza un archivo JSON que contiene registros de tweets y devuelve las 10 fechas\n",
        "    más comunes junto con el usuario más activo para cada fecha.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): La ruta del archivo JSON que contiene los registros de tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[datetime.date, str]]: Una lista de tuplas, donde cada tupla contiene una fecha\n",
        "        y el usuario más activo para esa fecha.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si no se encuentra el archivo especificado en file_path.\n",
        "    \"\"\"\n",
        "\n",
        "    # Paso 1: Lectura del archivo JSON\n",
        "    dates_dict = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    # Paso 2: Procesamiento de los datos\n",
        "    with open(file_path, 'r') as data:\n",
        "        for line_data in data:\n",
        "            tweet = json.loads(line_data)\n",
        "            tweet_date = tweet['date'].split('T')[0]\n",
        "            username = tweet['user']['username']\n",
        "\n",
        "            # Actualización del contador de tweets por usuario y fecha\n",
        "            dates_dict[tweet_date][username] += 1\n",
        "\n",
        "    # Paso 3: Determinación de las fechas más comunes\n",
        "    top_dates = sorted(dates_dict.keys(), key=lambda x: sum(dates_dict[x].values()), reverse=True)[:10]\n",
        "\n",
        "    # Paso 4: Obtención del usuario más activo por fecha\n",
        "    top_users = [max(dates_dict[date], key=dates_dict[date].get) for date in top_dates]\n",
        "\n",
        "    # Paso 5: Formateo de las fechas\n",
        "    top_dates = [datetime.strptime(date_str, \"%Y-%m-%d\").date() for date_str in top_dates]\n",
        "\n",
        "    # Paso 6: Agrupación de las fechas y usuarios\n",
        "    result = list(zip(top_dates, top_users))\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "r-kDeEWvOD05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***- Segundo intento:*** función `q1_time`\n",
        "\n",
        "La función `q1_time` procesa un archivo JSON que contiene registros de tweets y devuelve las 10 fechas más comunes junto con el usuario más activo para cada fecha.\n",
        "\n",
        "***Descripción detallada:***\n",
        "\n",
        "***1.   Obtención de los datos de fecha y usuario:***\n",
        "*   Primero se guardan los datos de fecha y nombre de usuario en una lista de listas, para poder contarlos correctamente.\n",
        "*   Se abre el archivo especificado en `file_path` y se lee línea por línea.\n",
        "*   Los datos se almacenan en una lista donde cada elemento es otra lista que contiene la fecha del tweet y el nombre de usuario del autor.\n",
        "\n",
        "***2.   Determinación de las fechas más comunes:***\n",
        "*   Se utiliza la clase `Counter()` junto con list comprehension para obtener las 10 fechas más comunes de todos los tweets.\n",
        "*   Se cuentan las ocurrencias de cada fecha en la lista de datos y se obtienen las 10 fechas más comunes utilizando el método `most_common(10)`.\n",
        "\n",
        "***3.   Obtención del usuario más activo por fecha:***\n",
        "*   De manera similar, se obtiene el usuario que más tweeteó para cada una de las fechas más comunes.\n",
        "*   Se filtran los datos para cada fecha común y se cuentan las ocurrencias de cada usuario.\n",
        "*   Se selecciona el usuario con mayor cantidad de tweets para cada fecha común.\n",
        "\n",
        "***4.   Formateo de las fechas y agrupación con los usuarios:***\n",
        "*   Se utilizan las fechas obtenidas anteriormente y se las convierte al formato `datetime.date` utilizando la función `datetime.strptime()`.\n",
        "*   Se combinan las fechas formateadas y los usuarios más activos en una lista de tuplas.\n",
        "\n",
        "***5.   Retorno de resultados:***\n",
        "*   La función devuelve la lista de tuplas que contiene las 10 fechas principales con los usuarios más activos para cada una de esas fechas.\n"
      ],
      "metadata": {
        "id": "OgjxxV2BPK6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q1_time_attempt_2(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "    \"\"\"\n",
        "    Esta función procesa un archivo JSON que contiene registros de tweets y devuelve las 10 fechas más comunes junto con el usuario más activo para cada fecha.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): La ruta del archivo JSON que contiene los registros de tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[datetime.date, str]]: Una lista de tuplas, donde cada tupla contiene una fecha y el usuario más activo para esa fecha.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si el archivo especificado en file_path no se encuentra.\n",
        "    \"\"\"\n",
        "    # Paso 1: Obtención de los datos de fecha y usuario\n",
        "    with open(file_path, 'r') as data:\n",
        "        tweets_dates_users = [[json.loads(line)['date'].split('T')[0], json.loads(line)['user']['username']] for line in data.readlines()]\n",
        "\n",
        "    # Paso 2: Determinación de las fechas más comunes\n",
        "    most_common_dates = Counter([d[0] for d in tweets_dates_users]).most_common(10)\n",
        "\n",
        "    # Paso 3: Obtención del usuario más activo para cada fecha más común\n",
        "    most_common_users = [Counter([d[1] for d in tweets_dates_users if d[0] == date[0]]).most_common(1)[0][0] for date in most_common_dates]\n",
        "\n",
        "    # Paso 4: Formateo de las fechas y agrupación con los usuarios\n",
        "    result = list(zip([datetime.strptime(date[0], \"%Y-%m-%d\").date() for date in most_common_dates], most_common_users))\n",
        "\n",
        "    # Paso 5: Retorno de resultados\n",
        "    return result"
      ],
      "metadata": {
        "id": "rECFJEOsPNLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***- Intento Final:*** función `q1_time`\n",
        "\n",
        "\n",
        "En este intento no se almacenan los datos directamente en una lista donde cada elemento es otra lista que contiene la fecha del tweet y el nombre de usuario del autor. Tampoco se utiliza la clase Counter para optimizar la ejecución de la función `q1_time`.\n",
        "\n",
        "***Descripción detallada:***\n",
        "\n",
        "***1.   Obtención de los datos de fecha y usuario:***\n",
        "*   Primero se leen todas las líneas del archivo JSON especificado en el parámetro `file_path`.\n",
        "*   Los datos se almacenan en una lista de listas, donde cada sublista contiene la fecha del tweet y el nombre de usuario del autor.\n",
        "\n",
        "***2.   Determinación de las fechas más comunes:***\n",
        "*   Se cuenta la frecuencia de cada fecha en la lista de datos para obtener las 10 fechas más comunes.\n",
        "*   No se utiliza la clase `Counter` para optimizar el código y se realiza el conteo manualmente.\n",
        "\n",
        "***3.   Obtención del usuario más activo por fecha:***\n",
        "*   Para cada una de las fechas más comunes, se filtran los datos y se cuentan las ocurrencias de cada usuario.\n",
        "*   Se selecciona el usuario con mayor cantidad de tweets para cada fecha común.\n",
        "\n",
        "***4.   Formateo de las fechas y agrupación con los usuarios:***\n",
        "*   Se utilizan las fechas obtenidas anteriormente y se las convierte al formato `datetime.date` utilizando la función `datetime.strptime()`.\n",
        "*   Se combinan las fechas formateadas y los usuarios más activos en una lista de tuplas.\n",
        "\n",
        "***5.   Retorno de resultados:***\n",
        "*   La función devuelve la lista de tuplas que contiene las 10 fechas principales con los usuarios más activos para cada una de esas fechas.\n"
      ],
      "metadata": {
        "id": "2Zp-R-3QPONr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "    \"\"\"\n",
        "    Esta función procesa un archivo JSON que contiene registros de tweets y devuelve las 10 fechas más comunes junto con el usuario más activo para cada fecha.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): La ruta del archivo JSON que contiene los registros de tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[datetime.date, str]]: Una lista de tuplas, donde cada tupla contiene una fecha y el usuario más activo para esa fecha.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si el archivo especificado en file_path no se encuentra.\n",
        "    \"\"\"\n",
        "    # Paso 1: Obtención de los datos de fecha y usuario\n",
        "    tweets_dates_users = []\n",
        "    with open(file_path, 'r') as data:\n",
        "        for line in data.readlines():\n",
        "            tweet = json.loads(line)\n",
        "            tweet_date = tweet['date'].split('T')[0]\n",
        "            username = tweet['user']['username']\n",
        "            tweets_dates_users.append((tweet_date, username))\n",
        "\n",
        "    # Paso 2: Determinación de las fechas más comunes\n",
        "    date_counts = {}\n",
        "    for tweet_date, _ in tweets_dates_users:\n",
        "        if tweet_date in date_counts:\n",
        "            date_counts[tweet_date] += 1\n",
        "        else:\n",
        "            date_counts[tweet_date] = 1\n",
        "    most_common_dates = sorted(date_counts.items(), key=lambda x: x[1],\n",
        "                               reverse=True)[:10]\n",
        "\n",
        "    # Paso 3: Obtención del usuario más activo para cada fecha más común\n",
        "    most_common_users = []\n",
        "    for date, _ in most_common_dates:\n",
        "        user_counts = {}\n",
        "        for tweet_date, username in tweets_dates_users:\n",
        "            if tweet_date == date:\n",
        "                if username in user_counts:\n",
        "                    user_counts[username] += 1\n",
        "                else:\n",
        "                    user_counts[username] = 1\n",
        "        most_common_user = max(user_counts, key=user_counts.get)\n",
        "        most_common_users.append(most_common_user)\n",
        "\n",
        "    # Paso 4: Formateo de las fechas y agrupación con los usuarios\n",
        "    result = [(datetime.strptime(date[0], \"%Y-%m-%d\").date(), user)\n",
        "                for date, user in zip(most_common_dates, most_common_users)]\n",
        "\n",
        "    # Paso 5: Retorno de resultados\n",
        "    return result"
      ],
      "metadata": {
        "id": "7OJ5FXOjPPZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## - Pruebas y Ejecución de la función `q1_time`\n",
        "\n",
        "De acuerdo a la documentación, para medir el tiempo de ejecución se recomienda el uso de [py-spy](https://github.com/benfred/py-spy) o [Python Profilers](https://docs.python.org/3/library/profile.html) sin embargo el uso de estas herramientas para una sola función lo considero engorroso ya que solo requiero medir el tiempo que tarda en ejecutarse la funcion `q1_time`.\n",
        "\n",
        "***1. Medición de tiempo:***\n",
        "\n",
        "Dada la explicación anterior, para la medición del tiempo de ejecución de `q1_time` solamente utilizo la función `time` nativa de Phyton para tomar un tiempo de inicio antes de la ejecución de la función y un tiempo final una vez culmina su ejecución luego calculo la diferencia entre ambos y obtengo la medición de tiempo requerida.\n",
        "\n",
        "***2. Ejecución de q1_time:***\n",
        "\n",
        "Se realiza la ejecición de de `q1_time` con `test_file_path` como argumento (base de datos) y se imprime su resultado.\n",
        "\n",
        "***3. Impresión de resultado \"Humanizado\":***\n",
        "\n",
        "Se imprime el mismo resultado anterior organizando la información para que resulta más facil de comprender."
      ],
      "metadata": {
        "id": "zGZFq36DWItj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Medir el tiempo de ejecución de q1_time_attempt_1\n",
        "start_time = time.time()\n",
        "q1_time_attempt_1(test_file_path)\n",
        "end_time = time.time()\n",
        "# Calcular el tiempo de ejecución\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Tiempo de ejecución de q1_time_attempt_1: {execution_time} s \\n\")\n",
        "\n",
        "# Medir el tiempo de ejecución de q1_time_attempt_2\n",
        "start_time = time.time()\n",
        "q1_time_attempt_2(test_file_path)\n",
        "end_time = time.time()\n",
        "# Calcular el tiempo de ejecución\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Tiempo de ejecución de q1_time_attempt_2: {execution_time} s \\n\")\n",
        "\n",
        "# Medir el tiempo de ejecución de q1_time\n",
        "start_time = time.time()\n",
        "results = q1_time(test_file_path)\n",
        "end_time = time.time()\n",
        "# Calcular el tiempo de ejecución\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Tiempo de ejecución de q1_time: {execution_time} s \\n\")\n",
        "\n",
        "# Imprimir los resultados obtenidos\n",
        "print(\"Resultados obtenidos:\")\n",
        "print(results, \"\\n\")\n",
        "\n",
        "print(\"Resultados humanizados:\")\n",
        "for i, (date, username) in enumerate(results, start=1):\n",
        "    print(f\"{i}. Fecha: {date}, Usuario con más publicaciones: {username}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rE-3wYvWKFt",
        "outputId": "3f40fe57-7b96-41e0-9358-1a50a3d1349d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de ejecución de q1_time_attempt_1: 7.153099298477173 s \n",
            "\n",
            "Tiempo de ejecución de q1_time_attempt_2: 9.681710720062256 s \n",
            "\n",
            "Tiempo de ejecución de q1_time: 7.5432960987091064 s \n",
            "\n",
            "Resultados obtenidos:\n",
            "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')] \n",
            "\n",
            "Resultados humanizados:\n",
            "1. Fecha: 2021-02-12, Usuario con más publicaciones: RanbirS00614606\n",
            "2. Fecha: 2021-02-13, Usuario con más publicaciones: MaanDee08215437\n",
            "3. Fecha: 2021-02-17, Usuario con más publicaciones: RaaJVinderkaur\n",
            "4. Fecha: 2021-02-16, Usuario con más publicaciones: jot__b\n",
            "5. Fecha: 2021-02-14, Usuario con más publicaciones: rebelpacifist\n",
            "6. Fecha: 2021-02-18, Usuario con más publicaciones: neetuanjle_nitu\n",
            "7. Fecha: 2021-02-15, Usuario con más publicaciones: jot__b\n",
            "8. Fecha: 2021-02-20, Usuario con más publicaciones: MangalJ23056160\n",
            "9. Fecha: 2021-02-23, Usuario con más publicaciones: Surrypuria\n",
            "10. Fecha: 2021-02-19, Usuario con más publicaciones: Preetm91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q1 Enfoque 2:** Optimización de la memoria en uso."
      ],
      "metadata": {
        "id": "vbtWtuyVOoly"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iWsKwkoIwKu"
      },
      "source": [
        "###***- Primer intento:*** función `q1_memory`\n",
        "\n",
        "La función `q1_memory` procesa un archivo JSON que contiene registros de tweets y devuelve las 10 fechas más comunes junto con el usuario más activo para cada fecha.\n",
        "\n",
        "En este primer intento no voy a usar librerias adicionales, utilizo simplemente un diccionario estándar `dates_dict` de Python para ir recolectando fechas y usuarios junto con el método `setdefault()`.\n",
        "\n",
        "La función `q1_memory_attemp_1` procesa un archivo JSON que contiene registros de tweets y devuelve las 10 fechas más comunes junto con el usuario más activo para cada fecha.\n",
        "\n",
        "***Descripción detallada:***\n",
        "\n",
        "***1.   Inicialización del diccionario de fechas y usuarios:***\n",
        "*   Se crea un diccionario llamado `dates_dict` para almacenar los pares de fecha-usuario y contar la cantidad de tweets por usuario en cada fecha.\n",
        "\n",
        "***2.   Procesamiento de los datos:***\n",
        "*   Se abre el archivo especificado en `file_path` en modo de lectura y se procesa línea por línea.\n",
        "*   Para cada línea, se carga el JSON y se extraen la fecha y el nombre de usuario del tweet.\n",
        "*   Se actualiza el contador de tweets por usuario y fecha en el diccionario `dates_dict`.\n",
        "\n",
        "***3.   Ordenamiento de las fechas según la cantidad total de tweets:***\n",
        "*   Se obtienen las fechas más comunes ordenando el diccionario `dates_dict` según la suma de los valores (número de tweets) de cada fecha.\n",
        "\n",
        "***4.   Obtención del usuario más activo por fecha:***\n",
        "*   Para cada fecha más común, se obtiene el usuario más activo (el que más tweets ha realizado) utilizando el método `max`.\n",
        "\n",
        "***5.   Formateo de las fechas:***\n",
        "*   Las fechas extraídas inicialmente están en formato de cadena de texto. Se utilizan para crear objetos `datetime.date` utilizando la función `datetime.strptime()` para convertirlas al formato deseado.\n",
        "\n",
        "***6.   Retorno de resultados:***\n",
        "*   La función devuelve una lista de tuplas, donde cada tupla contiene una fecha y el usuario más activo para esa fecha.\n",
        "\n",
        "Esta implementación proporciona una manera eficiente de analizar datos de tweets y obtener información sobre las fechas y usuarios más activos en la plataforma.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0Ytj0VsIwKu"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q1_memory_attempt_1(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "    \"\"\"\n",
        "    Esta función procesa un archivo JSON que contiene registros de tweets y devuelve las 10 fechas más comunes junto con el usuario más activo para cada fecha.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): La ruta del archivo JSON que contiene los registros de tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[datetime.date, str]]: Una lista de tuplas, donde cada tupla contiene una fecha y el usuario más activo para esa fecha.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si el archivo especificado en file_path no se encuentra.\n",
        "    \"\"\"\n",
        "    # Paso 1: Inicialización del diccionario de fechas y usuarios\n",
        "    dates_dict = {}\n",
        "\n",
        "    # Paso 2: Procesamiento de los datos\n",
        "    with open(file_path, 'r') as data:\n",
        "        for line_data in data:\n",
        "            tweet = json.loads(line_data)\n",
        "            tweet_date = tweet['date'].split('T')[0]\n",
        "            username = tweet['user']['username']\n",
        "\n",
        "            # Paso 3: Actualización del contador de tweets por usuario y fecha\n",
        "            if tweet_date not in dates_dict:\n",
        "                dates_dict[tweet_date] = {}\n",
        "\n",
        "            dates_dict[tweet_date].setdefault(username, 0)\n",
        "            dates_dict[tweet_date][username] += 1\n",
        "\n",
        "    # Paso 4: Ordenamiento de las fechas según la cantidad total de tweets\n",
        "    top_dates = sorted(dates_dict.keys(), key=lambda x: sum(dates_dict[x].values()), reverse=True)[:10]\n",
        "\n",
        "    # Paso 5: Obtención del usuario más activo por fecha\n",
        "    top_users = [max(dates_dict[date], key=dates_dict[date].get) for date in top_dates]\n",
        "\n",
        "    # Paso 6: Formateo de las fechas\n",
        "    top_dates = [datetime.strptime(date_str, \"%Y-%m-%d\").date() for date_str in top_dates]\n",
        "\n",
        "    # Paso 7: Retorno de resultados\n",
        "    return list(zip(top_dates, top_users))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###***- Segundo intento:*** función `q1_memory`\n",
        "\n",
        "En este otro intento, se proporciona una manera eficiente de analizar datos de tweets y obtener información sobre las fechas y usuarios más activos en la plataforma.\n",
        "\n",
        "La gran diferencia con el anterior es que al realizar la lectura del archivo, los datos se almacenan en una lista donde cada elemento es otra lista que contiene la fecha del tweet y el nombre de usuario del autor.\n",
        "\n",
        "***Descripción detallada:***\n",
        "\n",
        "***1.   Lectura del archivo JSON:***\n",
        "*   La función comienza abriendo el archivo JSON especificado en el parámetro `file_path` en modo de lectura.\n",
        "*   Lee línea por línea del archivo y carga los datos en un diccionario donde cada clave es la fecha del tweet y el valor es otro diccionario que almacena los usuarios y sus respectivos conteos de tweets.\n",
        "\n",
        "***2.   Procesamiento de los datos:***\n",
        "*   Para cada línea en el archivo, se extrae la fecha del tweet y el nombre de usuario del autor.\n",
        "*   Se actualiza el contador de tweets por usuario y fecha en el diccionario utilizando `setdefault()`.\n",
        "\n",
        "***3.   Determinación de las fechas más comunes:***\n",
        "*   Las fechas se ordenan según el número total de tweets publicados en cada una de ellas, utilizando `sorted()` y una función `key`.\n",
        "\n",
        "***4.   Obtención del usuario más activo por fecha:***\n",
        "*   Para cada una de las fechas más comunes, se determina el usuario más activo encontrando el usuario con el mayor número de tweets para esa fecha en particular.\n",
        "\n",
        "***5.   Formateo de las fechas:***\n",
        "*   Las fechas extraídas inicialmente están en formato de cadena de texto.\n",
        "*   Se utilizan para crear objetos `datetime.date` utilizando la función `datetime.strptime()` para convertirlas al formato deseado.\n",
        "\n",
        "***6.   Agrupación de las fechas y usuarios:***\n",
        "*   Se combinan las fechas formateadas y los usuarios más activos en una lista de tuplas.\n",
        "*   Cada tupla contiene una fecha y el usuario más activo para esa fecha.\n",
        "\n",
        "***7.   Retorno de resultados:***\n",
        "*   La función devuelve la lista de tuplas que contiene las 10 fechas principales con los usuarios más activos para cada una de esas fechas."
      ],
      "metadata": {
        "id": "GmhboTaN5_Le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q1_memory_attempt_2(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "    \"\"\"\n",
        "    Esta función procesa un archivo JSON que contiene registros de tweets y devuelve las 10 fechas más comunes junto con el usuario más activo para cada fecha.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): La ruta del archivo JSON que contiene los registros de tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[datetime.date, str]]: Una lista de tuplas, donde cada tupla contiene una fecha y el usuario más activo para esa fecha.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si el archivo especificado en file_path no se encuentra.\n",
        "    \"\"\"\n",
        "    # Paso 1: Inicialización del diccionario de fechas y usuarios\n",
        "    dates_dict = {}\n",
        "\n",
        "    # Paso 2: Procesamiento de los datos\n",
        "    with open(file_path, 'r') as data:\n",
        "        tweets_dates_users = [[json.loads(line)['date'].split('T')[0], json.loads(line)['user']['username']] for line in data.readlines()]\n",
        "\n",
        "    for tweet_date, username in tweets_dates_users:\n",
        "        # Paso 3: Actualización del contador de tweets por usuario y fecha\n",
        "        if tweet_date not in dates_dict:\n",
        "            dates_dict[tweet_date] = {}\n",
        "        dates_dict[tweet_date][username] = dates_dict[tweet_date].get(username, 0) + 1\n",
        "\n",
        "    # Paso 4: Ordenamiento de las fechas según la cantidad total de tweets\n",
        "    top_dates = sorted(dates_dict.keys(), key=lambda x: sum(dates_dict[x].values()), reverse=True)[:10]\n",
        "\n",
        "    # Paso 5: Obtención del usuario más activo por fecha\n",
        "    top_users = [max(dates_dict[date], key=dates_dict[date].get) for date in top_dates]\n",
        "\n",
        "    # Paso 6: Formateo de las fechas\n",
        "    top_dates = [datetime.strptime(date_str, \"%Y-%m-%d\").date() for date_str in top_dates]\n",
        "\n",
        "    # Paso 7: Retorno de resultados\n",
        "    return list(zip(top_dates, top_users))"
      ],
      "metadata": {
        "id": "43tUMrfd6AH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###***- Intento definitivo:*** función `q1_memory`\n",
        "\n",
        "Luego de intentar con los diccionarios estándar de Python, la solución más obvia a este problema es usar la clase `defaultdict` que se encuentra en el módulo `collections` de Python. Funciona de manera similar a un diccionario convencional (dict), pero con una diferencia clave: automáticamente crea valores por defecto para claves que aún no están en el diccionario. Esto significa que no es necesario preocuparse por verificar si una clave existe antes de acceder a ella o asignarle un valor.\n",
        "\n",
        "En esta implementación también se lee el archivo linea por linea para mejorar el uso de memoria y no cargar todo el archivo json en memoria.\n",
        "\n",
        "\n",
        "***Descripción detallada:***\n",
        "\n",
        "***1.   Lectura del archivo JSON:***\n",
        "*   La función comienza abriendo el archivo JSON especificado en el parámetro `file_path` en modo de lectura.\n",
        "*   Luego lee todas las líneas del archivo y carga los datos en una lista de listas.\n",
        "*   Cada sublista contiene la fecha del tweet y el nombre de usuario del autor del tweet.\n",
        "*   Estos datos se extraen del JSON utilizando la función `json.loads(line)['date'].split('T')[0]` para obtener la fecha y `json.loads(line)['user']['username']` para obtener el nombre de usuario.\n",
        "\n",
        "***2.   Procesamiento de los datos:***\n",
        "*   Se utiliza un diccionario para almacenar los pares fecha - usuario y sus respectivos conteos de tweets.\n",
        "*   Para cada tweet en el archivo, se extrae la fecha y el nombre de usuario.\n",
        "*   Luego, se actualiza el contador de tweets por usuario y fecha en el diccionario.\n",
        "\n",
        "***3.   Determinación de las fechas más comunes:***\n",
        "*   Utilizando `sorted()` y `key`, se determinan las 10 fechas más comunes en el diccionario.\n",
        "*   Las fechas se ordenan según el número total de tweets publicados en cada una de ellas.\n",
        "\n",
        "***4.   Obtención del usuario más activo por fecha:***\n",
        "*   Para cada una de las fechas más comunes, se determina el usuario más activo.\n",
        "*   Esto se logra encontrando el usuario con el mayor número de tweets para esa fecha en particular.\n",
        "\n",
        "***5.   Formateo de las fechas:***\n",
        "*   Las fechas extraídas inicialmente están en formato de cadena de texto.\n",
        "*   Se utilizan para crear objetos datetime.date utilizando la función `datetime.strptime()` para convertirlas al formato deseado.\n",
        "\n",
        "***6.   Agrupación de las fechas y usuarios:***\n",
        "*   Finalmente, se combinan las fechas formateadas y los usuarios más activos en una lista de tuplas.\n",
        "*   Cada tupla contiene una fecha y el usuario más activo para esa fecha.\n",
        "\n",
        "***7.   Retorno de resultados:***\n",
        "*   La función devuelve la lista de tuplas que contiene las 10 fechas principales con los usuarios más activos para cada una de esas fechas.\n",
        "*   Esta función proporciona una manera eficiente de analizar datos de tweets y obtener información sobre las fechas y usuarios más activos en la plataforma."
      ],
      "metadata": {
        "id": "dKn1y7d4fy68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "from datetime import datetime\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "    \"\"\"\n",
        "    Esta función analiza un archivo JSON que contiene registros de tweets y devuelve las 10 fechas\n",
        "    más comunes junto con el usuario más activo para cada fecha.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): La ruta del archivo JSON que contiene los registros de tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[datetime.date, str]]: Una lista de tuplas, donde cada tupla contiene una fecha\n",
        "        y el usuario más activo para esa fecha.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si no se encuentra el archivo especificado en file_path.\n",
        "    \"\"\"\n",
        "\n",
        "    # Paso 1: Lectura del archivo JSON\n",
        "    dates_dict = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    # Paso 2: Procesamiento de los datos\n",
        "    with open(file_path, 'r') as data:\n",
        "        for line_data in data:\n",
        "            tweet = json.loads(line_data)\n",
        "            tweet_date = tweet['date'].split('T')[0]\n",
        "            username = tweet['user']['username']\n",
        "\n",
        "            # Actualización del contador de tweets por usuario y fecha\n",
        "            dates_dict[tweet_date][username] += 1\n",
        "\n",
        "    # Paso 3: Determinación de las fechas más comunes\n",
        "    top_dates = sorted(dates_dict.keys(), key=lambda x: sum(dates_dict[x].values()), reverse=True)[:10]\n",
        "\n",
        "    # Paso 4: Obtención del usuario más activo por fecha\n",
        "    top_users = [max(dates_dict[date], key=dates_dict[date].get) for date in top_dates]\n",
        "\n",
        "    # Paso 5: Formateo de las fechas\n",
        "    top_dates = [datetime.strptime(date_str, \"%Y-%m-%d\").date() for date_str in top_dates]\n",
        "\n",
        "    # Paso 6: Agrupación de las fechas y usuarios\n",
        "    result = list(zip(top_dates, top_users))\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "hxAfh6zZcmRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2i790-lIwKv"
      },
      "source": [
        "## - Ejecuto la función `q1_memory`\n",
        "\n",
        "***Medición de memoria:***\n",
        "\n",
        "Utilizando memory_profiler para medir el uso de memoria de la función `q1_memory`. `memory_usage` devuelve una lista que contiene el uso de memoria en diferentes puntos de la ejecución de la función. En este caso, se pasa `(q1_memory, (test_file_path,))` como argumento a `memory_usage`, lo que significa que estás midiendo el uso de memoria de `q1_memory` con `test_file_path` como argumento (base de datos). Finalmente se imprime el usuo de memoria de `q1_memory`.\n",
        "\n",
        "***2. Ejecución de q1_memory:***\n",
        "\n",
        "Se realiza la ejecición de de `q1_memory` con `test_file_path` como argumento (base de datos) y se imprime su resultado.\n",
        "\n",
        "***3. Impresión de resultado \"Humanizado\":***\n",
        "\n",
        "Se imprime el mismo resultado anterior organizando la información para que resulta más facil de comprender.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_NA0pJjIwKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff50fdcc-7fca-45e0-9511-6dc503bfe0b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uso de memoria de q1_memory: 1015.05078125 MB \n",
            "\n",
            "Resultados obtenidos:\n",
            "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')] \n",
            "\n",
            "Resultados humanizados:\n",
            "1. Fecha: 2021-02-12, Usuario con más publicaciones: RanbirS00614606\n",
            "2. Fecha: 2021-02-13, Usuario con más publicaciones: MaanDee08215437\n",
            "3. Fecha: 2021-02-17, Usuario con más publicaciones: RaaJVinderkaur\n",
            "4. Fecha: 2021-02-16, Usuario con más publicaciones: jot__b\n",
            "5. Fecha: 2021-02-14, Usuario con más publicaciones: rebelpacifist\n",
            "6. Fecha: 2021-02-18, Usuario con más publicaciones: neetuanjle_nitu\n",
            "7. Fecha: 2021-02-15, Usuario con más publicaciones: jot__b\n",
            "8. Fecha: 2021-02-20, Usuario con más publicaciones: MangalJ23056160\n",
            "9. Fecha: 2021-02-23, Usuario con más publicaciones: Surrypuria\n",
            "10. Fecha: 2021-02-19, Usuario con más publicaciones: Preetm91\n"
          ]
        }
      ],
      "source": [
        "import memory_profiler\n",
        "\n",
        "# Medir el uso de memoria de q1_memory con memory-profiler\n",
        "mem_usage = memory_profiler.memory_usage((q1_memory, (test_file_path, )))\n",
        "\n",
        "# Imprimir el uso de memoria\n",
        "print(f\"Uso de memoria de q1_memory: {max(mem_usage)} MB \\n\")\n",
        "\n",
        "# Ejecutar q1_memory y obtener los resultados\n",
        "results = q1_memory(test_file_path)\n",
        "\n",
        "# Imprimir los resultados obtenidos\n",
        "print(\"Resultados obtenidos:\")\n",
        "print(results, \"\\n\")\n",
        "\n",
        "print(\"Resultados humanizados:\")\n",
        "for i, (date, username) in enumerate(results, start=1):\n",
        "    print(f\"{i}. Fecha: {date}, Usuario con más publicaciones: {username}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego de todas las pruebas, para este punto en el que se prioriza el uso de memoria, se opta por dejar la implementación de `q1_memory` con la implementación que usa `defaultdict` y la lectura del json linea por linea, ya que es la que mejores resultados arroja."
      ],
      "metadata": {
        "id": "6siYtj2LrlBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reto Q2**\n",
        "\n",
        "Los top 10 emojis más usados con su respectivo conteo. Debe incluir las siguientes funciones:\n",
        "```python\n",
        "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
        "```\n",
        "```python\n",
        "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
        "```\n",
        "```python\n",
        "Returns:\n",
        "[(\"✈️\", 6856), (\"❤️\", 5876), ...]\n",
        "```"
      ],
      "metadata": {
        "id": "6POLMQ5nmask"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q2 Enfoque 1:** Optimización del tiempo de ejecución."
      ],
      "metadata": {
        "id": "ldU8ixnLYz8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***- Primer intento:*** función `q2_time_attempt_1`\n",
        "\n",
        "En este intento lo que hago es buscar los emojis mapeando los caracteres y usando un diccionario estándar para contar la frecuencia de cada emoji. Aca se utiliza el método `json.load(f)` para cargar todos los tweets del archivo JSON en una lista de diccionarios.\n",
        "\n",
        "\n",
        "\n",
        "#### Descripción detallada:\n",
        "\n",
        "1. **Inicialización del diccionario de conteo de emojis:**\n",
        "   - Se crea un diccionario vacío llamado `emoji_counts` para almacenar la frecuencia de cada emoji.\n",
        "\n",
        "2. **Lectura del archivo JSON y procesamiento de los tweets:**\n",
        "   - Se abre el archivo JSON especificado en modo de lectura.\n",
        "   - Se leen todos los tweets de una vez y se almacenan en la lista `tweets`.\n",
        "   \n",
        "3. **Obtención del contenido de los tweets en un gran string:**\n",
        "   - Se inicializa una cadena vacía llamada `tweets_content` para almacenar el contenido de todos los tweets.\n",
        "   - Se itera sobre cada tweet en la lista `tweets`, se carga el contenido del tweet como un diccionario JSON y se agrega el contenido al string `tweets_content`.\n",
        "\n",
        "4. **Búsqueda de emojis en el gran string:**\n",
        "   - Se recorre cada caracter del string `tweets_content` y se verifica si es un emoji válido utilizando la función `map(chr, range(128, 1024))`.\n",
        "   - Los emojis válidos encontrados se agregan a la lista `all_emojis`.\n",
        "   \n",
        "5. **Conteo de la frecuencia de cada emoji:**\n",
        "   - Se itera sobre cada emoji en la lista `all_emojis`.\n",
        "   - Se actualiza el diccionario `emoji_counts` con la frecuencia de cada emoji.\n",
        "   \n",
        "6. **Obtención de los 10 emojis más utilizados:**\n",
        "   - Se ordena el diccionario `emoji_counts` según el valor de frecuencia de los emojis en orden descendente.\n",
        "   - Se seleccionan los 10 emojis más utilizados y se devuelven en una lista de tuplas.\n",
        "\n",
        "7. **Retorno de resultados:**\n",
        "   - La función devuelve una lista de tuplas que contiene los 10 emojis más utilizados junto con su respectivo conteo de ocurrencias.\n"
      ],
      "metadata": {
        "id": "9MOX7I3KY1Kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q2_time_attempt_1(file_path: str) -> List[Tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Encuentra los 10 emojis más utilizados en los tweets presentes en el archivo JSON especificado,\n",
        "    junto con su respectivo conteo de ocurrencias.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Ruta al archivo JSON que contiene los datos de los tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, int]]: Una lista de tuplas que contiene los 10 emojis más utilizados, cada una con su respectivo conteo de ocurrencias.\n",
        "    \"\"\"\n",
        "    # Paso 1: Inicialización de un diccionario para contar la frecuencia de cada emoji\n",
        "    emoji_counts = {}\n",
        "\n",
        "    # Paso 2: Lectura del archivo JSON y procesamiento de los tweets\n",
        "    with open(file_path, 'r') as data:\n",
        "        # Paso 3: Se obtienen todos los objetos de tweets de una vez\n",
        "        tweets = data.readlines()\n",
        "\n",
        "    # Paso 4: Se obtiene un gran string que contiene todos los contenidos de los tweets\n",
        "    tweets_content = \"\"\n",
        "    for tweet in tweets:\n",
        "        tweets_content += json.loads(tweet)['content']\n",
        "\n",
        "    # Paso 5: Obtención de todos los emojis presentes en el gran string\n",
        "    all_emojis = [char for char in tweets_content if char in ' '.join(map(chr, range(128, 1024)))]\n",
        "\n",
        "    # Paso 6: Conteo de la frecuencia de cada emoji y actualización del diccionario de conteo\n",
        "    for emoji in all_emojis:\n",
        "        emoji_counts[emoji] = emoji_counts.get(emoji, 0) + 1\n",
        "\n",
        "    # Paso 7: Obtención de los 10 emojis más utilizados con su respectivo conteo\n",
        "    top_10_emojis = sorted(emoji_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "    return top_10_emojis"
      ],
      "metadata": {
        "id": "Xl7dAXaWM30j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***- Segundo intento:*** función `q2_time`\n",
        "\n",
        "A diferencia de la implementación anterior, en donde busco los emojis comparando si están dentro del rango de códigos Unicode que representan emojis lo cual se prueba que es muy ineficiente, ahora en este intento utilizo la función `emoji_list` de la librería `emoji` para obtener los emojis presentes en el contenido de cada tweet, manteniendo el resto de la funcionalidad intacta.\n",
        "\n",
        "\n",
        "#### Descripción detallada:\n",
        "\n",
        "***1.   Inicialización del contador de emojis:***\n",
        "*   Se inicializa un diccionario vacío `emoji_counts` para contar la frecuencia de cada emoji encontrado en los tweets.\n",
        "\n",
        "***2.   Lectura del archivo JSON:***\n",
        "*   Se lee el archivo JSON especificado en el parámetro `file_path` y se almacenan todos los objetos de tweets de una vez en la lista `tweets`.\n",
        "\n",
        "***3.   Concatenación de los contenidos de los tweets:***\n",
        "*   Se recorren todos los tweets en la lista `tweets` y se concatenan sus contenidos en un solo gran string `tweets_content`.\n",
        "\n",
        "***4.   Obtención de los emojis presentes en los tweets:***\n",
        "*   Utilizando la función `emoji_list` se obtienen los emojis presentes en el gran string `tweets_content`. La función `emoji_list` devuelve una lista de diccionarios, donde cada diccionario contiene información sobre un emoji, incluyendo su representación Unicode.\n",
        "*   `[emoji['emoji'] for emoji in emoji_list(tweets_content)]` Utiliza una list comprehension para extraer solo la representación Unicode de cada emoji de la lista de diccionarios devuelta por `emoji_list`, y almacena estas representaciones en la lista `emojis_in_tweets`. Esto asegura que solo se obtenga la representación Unicode de cada emoji y no se incluyan otros detalles del diccionario.\n",
        "\n",
        "***5.   Actualización del contador de emojis:***\n",
        "*   Se recorren todos los emojis presentes en la lista `emojis_in_tweets` y se actualiza el contador de emojis `emoji_counts` con la frecuencia de cada emoji.\n",
        "\n",
        "***6.   Obtención de los 10 emojis más utilizados:***\n",
        "*   Se ordena el diccionario `emoji_counts` por sus valores en orden descendente para obtener los emojis más utilizados.\n",
        "*   Se seleccionan los primeros 10 elementos del diccionario ordenado para obtener los 10 emojis más utilizados junto con su respectivo conteo de ocurrencias.\n",
        "\n",
        "***7.   Retorno de resultados:***\n",
        "*   La función devuelve una lista de tuplas que contiene los 10 emojis más utilizados, donde cada tupla tiene la forma `(emoji, conteo)`.\n"
      ],
      "metadata": {
        "id": "pGTHu8T0ZHwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from emoji import emoji_list\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q2_time_attempt_2(file_path: str) -> List[Tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Encuentra los 10 emojis más utilizados en los tweets presentes en el archivo JSON especificado,\n",
        "    junto con su respectivo conteo de ocurrencias.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Ruta al archivo JSON que contiene los datos de los tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, int]]: Una lista de tuplas que contiene los 10 emojis más utilizados, cada una con su respectivo conteo de ocurrencias.\n",
        "    \"\"\"\n",
        "    # Paso 1: Se inicializa un diccionario para contar la frecuencia de cada emoji\n",
        "    emoji_counts = {}\n",
        "\n",
        "    # Paso 2: Se obtienen todos los objetos de tweets de una vez\n",
        "    with open(file_path, 'r') as data:\n",
        "        tweets = data.readlines()\n",
        "\n",
        "    # Paso 3: Se obtiene un gran string que contiene todos los contenidos de los tweets\n",
        "    tweets_content = \"\"\n",
        "    for tweet in tweets:\n",
        "        tweets_content += json.loads(tweet)['content']\n",
        "\n",
        "    # Paso 4: Se obtienen los emojis presentes en el gran string utilizando emoji_list\n",
        "    emojis_in_tweets = [emoji['emoji'] for emoji in emoji_list(tweets_content)]\n",
        "\n",
        "    # Paso 5: Se actualiza el contador de emojis con la frecuencia de cada emoji\n",
        "    for emoji in emojis_in_tweets:\n",
        "        emoji_counts[emoji] = emoji_counts.get(emoji, 0) + 1\n",
        "\n",
        "    # Paso 6: Se obtienen los 10 emojis más utilizados con su respectivo conteo\n",
        "    top_10_emojis = sorted(emoji_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "    return top_10_emojis"
      ],
      "metadata": {
        "id": "TWQcP26bZORA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###***- Intento definitivo:*** función `q2_time`\n",
        "\n",
        "\n",
        "En esta versión final, se utiliza la clase `Counter`, que es una clase en Python que se encuentra en el módulo `collections` y que me permite contar la ocurrencia de elementos en una secuencia y generar un diccionario con las frecuencias de esos elementos para contar la ocurrencia de emojis.\n",
        "\n",
        "En lugar de iterar manualmente sobre los tweets y acumular los emojis, se utiliza un enfoque más eficiente. El uso de Counter simplifica significativamente el proceso y mejora la eficiencia del código en términos de legibilidad y rendimiento.\n",
        "\n",
        "\n",
        "#### Detalles de la Implementación\n",
        "\n",
        "1. **Inicialización del contador de emojis:**\n",
        "   Se inicializa un objeto `Counter` para contar la frecuencia de cada emoji en los tweets.\n",
        "\n",
        "2. **Lectura del archivo JSON y procesamiento de los tweets:**\n",
        "   Se abre el archivo JSON especificado en modo de lectura y se recorren todas las líneas.\n",
        "   Para cada línea, se carga el contenido del tweet como un diccionario JSON y se extraen los emojis presentes en el contenido del tweet.\n",
        "\n",
        "3. **Obtención de los emojis de cada línea:**\n",
        "   Se utiliza la función `emoji_list` para obtener una lista de emojis presentes en el contenido del tweet.\n",
        "\n",
        "4. **Actualización del contador de emojis:**\n",
        "   Se actualiza el contador de emojis utilizando el método `update` del objeto `Counter` con la lista de emojis obtenida en el paso anterior.\n",
        "\n",
        "5. **Devolución de los 10 emojis más utilizados:**\n",
        "   Se devuelve una lista con los 10 emojis más utilizados junto con sus respectivos conteos de ocurrencias, utilizando el método `most_common` del objeto `Counter`."
      ],
      "metadata": {
        "id": "2jMlwueFeDeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "from emoji import emoji_list\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q2_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "    \"\"\"\n",
        "    Esta función procesa un archivo JSON que contiene registros de tweets y devuelve los 10 emojis más utilizados,\n",
        "    junto con su respectivo conteo de ocurrencias.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): La ruta del archivo JSON que contiene los datos de los tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, int]]: Una lista de tuplas que contiene los 10 emojis más utilizados,\n",
        "        cada una con su respectivo conteo de ocurrencias.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si el archivo especificado en file_path no se encuentra.\n",
        "    \"\"\"\n",
        "\n",
        "    # Paso 1: Inicialización del contador de emojis\n",
        "    emoji_counter = Counter()\n",
        "\n",
        "    # Paso 2: Lectura del archivo JSON y procesamiento de los tweets\n",
        "    with open(file_path, 'r') as data:\n",
        "        for line in data:\n",
        "            tweet_content = json.loads(line)['content']\n",
        "\n",
        "            # Paso 3: Obtención de los emojis de cada línea\n",
        "            tweet_emojis = [emoji['emoji'] for emoji in emoji_list(tweet_content)]\n",
        "\n",
        "            # Paso 4: Actualización del contador de emojis\n",
        "            emoji_counter.update(tweet_emojis)\n",
        "\n",
        "    # Paso 5: Devolución de los 10 emojis más utilizados\n",
        "    return emoji_counter.most_common(10)"
      ],
      "metadata": {
        "id": "2-iOaoWqeEhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## - Pruebas y Ejecución de la función `q2_time`\n",
        "\n",
        "Al igual que en el primer reto, solo se utiliza la libreria `time` para la medición del tiempo que tarda en ejecutarse la funcion `q2_time`.\n",
        "\n",
        "***1. Medición de tiempo:***\n",
        "\n",
        "Dada la explicación anterior, para la medición del tiempo de ejecución de `q2_time` solamente utilizo la función `time` nativa de Phyton para tomar un tiempo de inicio antes de la ejecución de la función y un tiempo final una vez culmina su ejecución luego calculo la diferencia entre ambos y obtengo la medición de tiempo requerida.\n",
        "\n",
        "***2. Ejecución de q2_time:***\n",
        "\n",
        "Se realiza la ejecición de de `q2_time` con `test_file_path` como argumento (base de datos) y se imprime su resultado.\n",
        "\n",
        "***3. Impresión de resultado \"Humanizado\":***\n",
        "\n",
        "Se imprime el mismo resultado anterior organizando la información para que resulta más facil de comprender."
      ],
      "metadata": {
        "id": "FnaHHxHhddA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Medir el tiempo de ejecución de q2_time\n",
        "start_time = time.time()\n",
        "results = q2_time(test_file_path)\n",
        "end_time = time.time()\n",
        "# Calcular el tiempo de ejecución\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Tiempo de ejecución de q2_time: {execution_time} s \\n\")\n",
        "\n",
        "# Imprimir los resultados obtenidos\n",
        "print(\"Resultados obtenidos:\")\n",
        "print(results, \"\\n\")\n",
        "\n",
        "print(\"Resultados humanizados:\")\n",
        "for i, (date, username) in enumerate(results, start=1):\n",
        "    print(f\"{i}. Fecha: {date}, Usuario con más publicaciones: {username}\")"
      ],
      "metadata": {
        "id": "47gWyUHpdw4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7040143-377f-4ad8-dd99-de38ae67cc80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de ejecución de q2_time: 23.365424394607544 s \n",
            "\n",
            "Resultados obtenidos:\n",
            "[('🙏', 5049), ('😂', 3072), ('🚜', 2972), ('🌾', 2182), ('🇮🇳', 2086), ('🤣', 1668), ('✊', 1651), ('❤️', 1382), ('🙏🏻', 1317), ('💚', 1040)] \n",
            "\n",
            "Resultados humanizados:\n",
            "1. Fecha: 🙏, Usuario con más publicaciones: 5049\n",
            "2. Fecha: 😂, Usuario con más publicaciones: 3072\n",
            "3. Fecha: 🚜, Usuario con más publicaciones: 2972\n",
            "4. Fecha: 🌾, Usuario con más publicaciones: 2182\n",
            "5. Fecha: 🇮🇳, Usuario con más publicaciones: 2086\n",
            "6. Fecha: 🤣, Usuario con más publicaciones: 1668\n",
            "7. Fecha: ✊, Usuario con más publicaciones: 1651\n",
            "8. Fecha: ❤️, Usuario con más publicaciones: 1382\n",
            "9. Fecha: 🙏🏻, Usuario con más publicaciones: 1317\n",
            "10. Fecha: 💚, Usuario con más publicaciones: 1040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##***Conclusión*** `q2_time`\n",
        "\n",
        "Los intentos 1 y 2 se intentaron hacer utilizando el minimo de funciones adicionales, en el primero de ellos usando representación Unicode de cada emoji para hacer la búsqueda y en el segundo usando `emoji_list()`, pero al revisar su ejecución y los resultados que se obtienen no son satisfactorios, puesto que muchos Unicodes los malinterpreta y el proceso de búsqueda es muy lento.\n",
        "\n",
        "En la versión final se utilizan `Counter` y `emoji_list` de manera que se crea una manera simple y eficiente de hacer la búsqueda y conteo de los emojis sobre la base de datos y después de todos los intentos se obtiene en esta implementación el mejor tiempo de respuesta."
      ],
      "metadata": {
        "id": "ovhtScTi4qIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q2 Enfoque 2:** Optimización de la memoria en uso.\n"
      ],
      "metadata": {
        "id": "Z8UVf3akuORo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###***- Primer intento:*** función `q2_memory`\n",
        "\n",
        "En este primer intento se toma el primer intento realizado en `q2_time`, pero para optimizar el uso de memoria en esta función se procesa cada tweet línea por línea directamente desde el archivo, evitando cargar todo el contenido del archivo en memoria.\n",
        "\n",
        "En este intento, procesamos cada línea del archivo directamente en el bucle `for line in data`. Esto reduce la carga de memoria al no necesitar almacenar todas las líneas en una lista antes de procesarlas.\n",
        "\n",
        "\n",
        "#### Descripción detallada:\n",
        "\n",
        "1. **Inicialización del diccionario de conteo de emojis:**\n",
        "   - Se crea un diccionario vacío llamado `emoji_counts` para almacenar la frecuencia de cada emoji.\n",
        "\n",
        "2. **Lectura del archivo JSON y procesamiento de los tweets:**\n",
        "   - Se abre el archivo JSON especificado en modo de lectura.\n",
        "   - Se leen todos los tweets de una vez y se almacenan en la lista `tweets`.\n",
        "   \n",
        "3. **Obtención del contenido de los tweets en un gran string:**\n",
        "   - Se inicializa una cadena vacía llamada `tweets_content` para almacenar el contenido de todos los tweets.\n",
        "   - Se itera sobre cada tweet en la lista `tweets`, se carga el contenido del tweet como un diccionario JSON y se agrega el contenido al string `tweets_content`.\n",
        "\n",
        "4. **Búsqueda de emojis en el gran string:**\n",
        "   - Se recorre cada caracter del string `tweets_content` y se verifica si es un emoji válido utilizando la función `map(chr, range(128, 1024))`.\n",
        "   - Los emojis válidos encontrados se agregan a la lista `all_emojis`.\n",
        "   \n",
        "5. **Conteo de la frecuencia de cada emoji:**\n",
        "   - Se itera sobre cada emoji en la lista `all_emojis`.\n",
        "   - Se actualiza el diccionario `emoji_counts` con la frecuencia de cada emoji.\n",
        "   \n",
        "6. **Obtención de los 10 emojis más utilizados:**\n",
        "   - Se ordena el diccionario `emoji_counts` según el valor de frecuencia de los emojis en orden descendente.\n",
        "   - Se seleccionan los 10 emojis más utilizados y se devuelven en una lista de tuplas.\n",
        "\n",
        "7. **Retorno de resultados:**\n",
        "   - La función devuelve una lista de tuplas que contiene los 10 emojis más utilizados junto con su respectivo conteo de ocurrencias.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ap92_Ya_uWog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q2_memory_attempt_1(file_path: str) -> List[Tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Encuentra los 10 emojis más utilizados en los tweets presentes en el archivo JSON especificado,\n",
        "    junto con su respectivo conteo de ocurrencias.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Ruta al archivo JSON que contiene los datos de los tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, int]]: Una lista de tuplas que contiene los 10 emojis más utilizados, cada una con su respectivo conteo de ocurrencias.\n",
        "    \"\"\"\n",
        "    # Paso 1: Inicialización de un diccionario para contar la frecuencia de cada emoji\n",
        "    emoji_counts = {}\n",
        "\n",
        "    # Paso 2: Lectura del archivo JSON y procesamiento de los tweets línea por línea\n",
        "    with open(file_path, 'r') as data:\n",
        "        for line in data:\n",
        "            # Paso 3: Cargar el contenido del tweet como un diccionario\n",
        "            tweet = json.loads(line)\n",
        "\n",
        "            # Paso 4: Obtener los emojis presentes en el contenido del tweet\n",
        "            tweet_content = tweet['content']\n",
        "            emojis_in_tweet = [char for char in tweet_content if char in ' '.join(map(chr, range(128, 1024)))]\n",
        "\n",
        "            # Paso 5: Actualización del contador de emojis con la frecuencia de cada emoji en el tweet\n",
        "            for emoji in emojis_in_tweet:\n",
        "                emoji_counts[emoji] = emoji_counts.get(emoji, 0) + 1\n",
        "\n",
        "    # Paso 6: Obtención de los 10 emojis más utilizados con su respectivo conteo\n",
        "    top_10_emojis = sorted(emoji_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "    return top_10_emojis\n"
      ],
      "metadata": {
        "id": "kKnEdv13ucX1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###***- Segundo intento:*** función `q2_memory`\n",
        "\n",
        "En este intento de `q2_memory` tomo como base el correspondiente intento de `q2_time` en donde utilizo `emoji_list()` para hacer la búsqueda de los emojis y se hace la lectura del archivo JSON y procesamiento de los tweets línea por línea para optimizar el manejo de memoria.\n",
        "\n",
        "\n",
        "#### Descripción detallada:\n",
        "\n",
        "1. **Inicialización del diccionario de conteo de emojis:**\n",
        "   - Se crea un diccionario vacío llamado `emoji_counts` para almacenar la frecuencia de cada emoji.\n",
        "\n",
        "2. **Lectura del archivo JSON y procesamiento de los tweets línea por línea:**\n",
        "   - Se abre el archivo JSON especificado en modo de lectura.\n",
        "   - Se itera sobre cada línea del archivo para procesar cada tweet individualmente.\n",
        "\n",
        "3. **Cargar el contenido del tweet como un diccionario:**\n",
        "   - Se carga el contenido del tweet como un diccionario JSON utilizando la función `json.loads()`.\n",
        "\n",
        "4. **Obtención de los emojis presentes en el contenido del tweet:**\n",
        "   - Se extrae el contenido del tweet y se obtienen los emojis presentes en él utilizando la función `emoji_list()` del módulo `emoji`.\n",
        "   - Los emojis se almacenan en una lista llamada `emojis_in_tweet`.\n",
        "\n",
        "5. **Actualización del contador de emojis con la frecuencia de cada emoji en el tweet:**\n",
        "   - Se itera sobre cada emoji en la lista `emojis_in_tweet`.\n",
        "   - Se actualiza el diccionario `emoji_counts` con la frecuencia de cada emoji.\n",
        "\n",
        "6. **Obtención de los 10 emojis más utilizados:**\n",
        "   - Se ordena el diccionario `emoji_counts` según el valor de frecuencia de los emojis en orden descendente.\n",
        "   - Se seleccionan los 10 emojis más utilizados y se devuelven en una lista de tuplas.\n",
        "\n",
        "Este intento utiliza la función `emoji_list()` del módulo `emoji` para obtener los emojis presentes en el contenido de cada tweet, sin la necesidad de usar ninguna librería adicional.\n"
      ],
      "metadata": {
        "id": "5Y0wvHk26cRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Tuple\n",
        "from emoji import emoji_list\n",
        "\n",
        "def q2_memory_attempt_2(file_path: str) -> List[Tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Encuentra los 10 emojis más utilizados en los tweets presentes en el archivo JSON especificado,\n",
        "    junto con su respectivo conteo de ocurrencias.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Ruta al archivo JSON que contiene los datos de los tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, int]]: Una lista de tuplas que contiene los 10 emojis más utilizados, cada una con su respectivo conteo de ocurrencias.\n",
        "    \"\"\"\n",
        "    # Paso 1: Inicialización de un diccionario para contar la frecuencia de cada emoji\n",
        "    emoji_counts = {}\n",
        "\n",
        "    # Paso 2: Lectura del archivo JSON y procesamiento de los tweets línea por línea\n",
        "    with open(file_path, 'r') as data:\n",
        "        for line in data:\n",
        "            # Paso 3: Cargar el contenido del tweet como un diccionario\n",
        "            tweet = json.loads(line)\n",
        "\n",
        "            # Paso 4: Obtener los emojis presentes en el contenido del tweet\n",
        "            tweet_content = tweet['content']\n",
        "            emojis_in_tweet = [emoji['emoji'] for emoji in emoji_list(tweet_content)]\n",
        "\n",
        "            # Paso 5: Actualización del contador de emojis con la frecuencia de cada emoji en el tweet\n",
        "            for emoji in emojis_in_tweet:\n",
        "                emoji_counts[emoji] = emoji_counts.get(emoji, 0) + 1\n",
        "\n",
        "    # Paso 6: Obtención de los 10 emojis más utilizados con su respectivo conteo\n",
        "    top_10_emojis = sorted(emoji_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "    return top_10_emojis\n"
      ],
      "metadata": {
        "id": "0MJhu3M36dFT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###***- Intento definitivo:*** función `q2_memory`"
      ],
      "metadata": {
        "id": "e2Y8d73b8LGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "from emoji import emoji_list\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Esta función procesa un archivo JSON que contiene registros de tweets y devuelve los 10 emojis más utilizados,\n",
        "    junto con su respectivo conteo de ocurrencias.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): La ruta del archivo JSON que contiene los datos de los tweets.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, int]]: Una lista de tuplas que contiene los 10 emojis más utilizados,\n",
        "        cada una con su respectivo conteo de ocurrencias.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si el archivo especificado en file_path no se encuentra.\n",
        "    \"\"\"\n",
        "\n",
        "    # Inicialización del contador de emojis\n",
        "    emoji_counter = Counter()\n",
        "\n",
        "    # Lectura del archivo JSON y procesamiento de los tweets\n",
        "    with open(file_path, 'r') as data:\n",
        "        for line in data:\n",
        "            tweet_content = json.loads(line)['content']\n",
        "\n",
        "            # Obtención de los emojis de cada línea\n",
        "            tweet_emojis = [emoji['emoji'] for emoji in emoji_list(tweet_content)]\n",
        "\n",
        "            # Actualización del contador de emojis\n",
        "            emoji_counter.update(tweet_emojis)\n",
        "\n",
        "    # Devolución de los 10 emojis más utilizados\n",
        "    return emoji_counter.most_common(10)\n"
      ],
      "metadata": {
        "id": "njS67x2I8MgX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## - Ejecuto la función `q2_memory`\n",
        "\n",
        "***Medición de memoria:***\n",
        "\n",
        "Utilizando memory_profiler para medir el uso de memoria de la función `q1_memory`. `memory_usage` devuelve una lista que contiene el uso de memoria en diferentes puntos de la ejecución de la función. En este caso, se pasa `(q2_memory, (test_file_path,))` como argumento a `memory_usage`, lo que significa que estás midiendo el uso de memoria de `q2_memory` con `test_file_path` como argumento (base de datos). Finalmente se imprime el usuo de memoria de `q2_memory`.\n",
        "\n",
        "***2. Ejecución de q2_memory:***\n",
        "\n",
        "Se realiza la ejecición de de `q2_memory` con `test_file_path` como argumento (base de datos) y se imprime su resultado.\n",
        "\n",
        "***3. Impresión de resultado \"Humanizado\":***\n",
        "\n",
        "Se imprime el mismo resultado anterior organizando la información para que resulta más facil de comprender."
      ],
      "metadata": {
        "id": "EgLoZeCK8Nqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import memory_profiler\n",
        "\n",
        "# Medir el uso de memoria de q1_memory con memory-profiler\n",
        "mem_usage = memory_profiler.memory_usage((q2_memory, (test_file_path, )))\n",
        "\n",
        "# Imprimir el uso de memoria\n",
        "print(f\"Uso de memoria de q1_memory: {max(mem_usage)} MB \\n\")\n",
        "\n",
        "# Ejecutar q1_memory y obtener los resultados\n",
        "results = q2_memory(test_file_path)\n",
        "\n",
        "# Imprimir los resultados obtenidos\n",
        "print(\"Resultados obtenidos:\")\n",
        "print(results, \"\\n\")\n",
        "\n",
        "print(\"Resultados humanizados:\")\n",
        "for i, (date, username) in enumerate(results, start=1):\n",
        "    print(f\"{i}. Fecha: {date}, Usuario con más publicaciones: {username}\")"
      ],
      "metadata": {
        "id": "yX7GRMiY8O6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a231a07-f4b7-4640-8e90-ef3562934c5c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uso de memoria de q1_memory: 172.3203125 MB \n",
            "\n",
            "Resultados obtenidos:\n",
            "[('🙏', 5049), ('😂', 3072), ('🚜', 2972), ('🌾', 2182), ('🇮🇳', 2086), ('🤣', 1668), ('✊', 1651), ('❤️', 1382), ('🙏🏻', 1317), ('💚', 1040)] \n",
            "\n",
            "Resultados humanizados:\n",
            "1. Fecha: 🙏, Usuario con más publicaciones: 5049\n",
            "2. Fecha: 😂, Usuario con más publicaciones: 3072\n",
            "3. Fecha: 🚜, Usuario con más publicaciones: 2972\n",
            "4. Fecha: 🌾, Usuario con más publicaciones: 2182\n",
            "5. Fecha: 🇮🇳, Usuario con más publicaciones: 2086\n",
            "6. Fecha: 🤣, Usuario con más publicaciones: 1668\n",
            "7. Fecha: ✊, Usuario con más publicaciones: 1651\n",
            "8. Fecha: ❤️, Usuario con más publicaciones: 1382\n",
            "9. Fecha: 🙏🏻, Usuario con más publicaciones: 1317\n",
            "10. Fecha: 💚, Usuario con más publicaciones: 1040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##***Conclusión*** `q2_memory`\n",
        "\n",
        "Semejante que con q2_time, los intentos 1 y 2 se intentaron hacer utilizando el minimo de funciones adicionales, en el primero de ellos usando representación Unicode de cada emoji para hacer la búsqueda y en el segundo usando `emoji_list()`, pero al revisar su ejecución y los resultados que se obtienen no son satisfactorios, puesto que muchos Unicodes los malinterpreta y el proceso de búsqueda es muy lento.\n",
        "\n",
        "En la versión final se utilizan `Counter`, `emoji_list()`, junto con un recorrido linea a linea del archivo para evitar la sobrecarga en memoria de información y asi, de esta manera se crea una manera simple y eficiente de hacer la búsqueda y conteo de los emojis sobre la base de datos y después de todos los intentos se obtiene en esta implementación el mejor tiempo de respuesta."
      ],
      "metadata": {
        "id": "90_ffQDT8Pr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reto Q3**\n",
        "\n",
        "\n",
        "El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos. Debe incluir las siguientes funciones:\n",
        "```python\n",
        "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
        "```\n",
        "```python\n",
        "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
        "```\n",
        "```python\n",
        "Returns:\n",
        "[(\"LATAM321\", 387), (\"LATAM_CHI\", 129), ...]\n",
        "```"
      ],
      "metadata": {
        "id": "9VAVfvS3mnwk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q3 Enfoque 1:** Optimización del tiempo de ejecución."
      ],
      "metadata": {
        "id": "UoUk68zRux87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###***- Intento definitivo:*** función `q3_time`\n",
        "\n",
        "\n",
        "En esta versión final, se utiliza la clase `Counter`, que es una clase en Python que se encuentra en el módulo `collections` y que me permite contar la ocurrencia de elementos en una secuencia y generar un diccionario con las frecuencias de esos elementos para contar la ocurrencia de emojis.\n",
        "\n",
        "En lugar de iterar manualmente sobre los tweets y acumular los emojis, se utiliza un enfoque más eficiente. El uso de Counter simplifica significativamente el proceso y mejora la eficiencia del código en términos de legibilidad y rendimiento.\n",
        "\n",
        "\n",
        "#### Detalles de la Implementación\n",
        "\n",
        "1. **Inicialización del contador de emojis:**\n",
        "   Se inicializa un objeto `Counter` para contar la frecuencia de cada emoji en los tweets.\n",
        "\n",
        "2. **Lectura del archivo JSON y procesamiento de los tweets:**\n",
        "   Se abre el archivo JSON especificado en modo de lectura y se recorren todas las líneas.\n",
        "   Para cada línea, se carga el contenido del tweet como un diccionario JSON y se extraen los emojis presentes en el contenido del tweet.\n",
        "\n",
        "3. **Obtención de los emojis de cada línea:**\n",
        "   Se utiliza la función `emoji_list` para obtener una lista de emojis presentes en el contenido del tweet.\n",
        "\n",
        "4. **Actualización del contador de emojis:**\n",
        "   Se actualiza el contador de emojis utilizando el método `update` del objeto `Counter` con la lista de emojis obtenida en el paso anterior.\n",
        "\n",
        "5. **Devolución de los 10 emojis más utilizados:**\n",
        "   Se devuelve una lista con los 10 emojis más utilizados junto con sus respectivos conteos de ocurrencias, utilizando el método `most_common` del objeto `Counter`."
      ],
      "metadata": {
        "id": "hlwWhOZ1vEa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# **Reto Q3**"
      ],
      "metadata": {
        "id": "-ANAv7-rmlCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##***Conclusión*** `q2_memory`\n",
        "\n",
        "Los intentos 1 y 2 se intentaron hacer utilizando el minimo de funciones adicionales y  la representación Unicode de cada emoji, pero al revisar su ejecución y los resultados que se obtienen no son satisfactorios, puesto que muchos Unicodes los malinterpreta y el proceso de búsqueda es muy lento.\n",
        "\n",
        "En la versión final se utilizan `Counter` y `emoji_list` de manera que se crea una manera simple y eficiente de hacer la búsqueda y conteo de los emojis sobre la base de datos y después de todos los intentos se obtiene en esta implementación el mejor tiempo de respuesta."
      ],
      "metadata": {
        "id": "gw7SkPAL570S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Enfoque 2:** Optimización de la memoria en uso."
      ],
      "metadata": {
        "id": "mhyzjTYxu4at"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.2"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}